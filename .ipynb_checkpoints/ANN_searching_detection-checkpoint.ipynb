{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>date</th>\n",
       "      <th>speed</th>\n",
       "      <th>double_cross</th>\n",
       "      <th>time_in_range</th>\n",
       "      <th>cluster_proximity</th>\n",
       "      <th>searching</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.093136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.232999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.093136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.232999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>1</td>\n",
       "      <td>4.294210</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.235498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>2</td>\n",
       "      <td>5.172045</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.239810</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>-0.000167</td>\n",
       "      <td>3</td>\n",
       "      <td>6.448076</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.245374</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       lat       lon  date     speed  double_cross  \\\n",
       "0           0  0.000000  0.000000     0  3.093136             0   \n",
       "1           1  0.000000  0.000000     0  3.093136             0   \n",
       "2           2  0.000039 -0.000033     1  4.294210             0   \n",
       "3           3  0.000070 -0.000096     2  5.172045             0   \n",
       "4           4  0.000122 -0.000167     3  6.448076             0   \n",
       "\n",
       "   time_in_range  cluster_proximity  searching  \n",
       "0              0           0.232999          0  \n",
       "1              0           0.232999          0  \n",
       "2              1           0.235498          0  \n",
       "3              2           0.239810          0  \n",
       "4              3           0.245374          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TUTORIAL: https://heartbeat.fritz.ai/introduction-to-deep-learning-with-keras-c7c3d14e1527\n",
    "\n",
    "df = pd.read_csv('dataset/ANN/training.csv')\n",
    "\n",
    "#If you have categorical values, transform them to dummy variables\n",
    "#feats = [‘policy_state’,’insured_sex’,’insured_education_level’,’insured_occupation’,’insured_hobbies’,’insured_relationship’,’collision_type’,’incident_severity’,’authorities_contacted’,’incident_state’,’incident_city’,’incident_location’,’property_damage’,’police_report_available’,’auto_make’,’auto_model’,’fraud_reported’,’incident_type’]\n",
    "#df_final = pd.get_dummies(df,columns=feats,drop_first=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3.09313560e+00, 0.00000000e+00, 0.00000000e+00, 2.32998684e-01],\n",
       "        [3.09313560e+00, 0.00000000e+00, 0.00000000e+00, 2.32998684e-01],\n",
       "        [4.29421002e+00, 0.00000000e+00, 1.00000000e+00, 2.35497885e-01],\n",
       "        ...,\n",
       "        [2.39999995e-01, 0.00000000e+00, 5.80000000e+01, 3.28557865e-03],\n",
       "        [2.39999995e-01, 0.00000000e+00, 5.90000000e+01, 3.28557865e-03],\n",
       "        [2.39999995e-01, 0.00000000e+00, 6.00000000e+01, 3.28557865e-03]]),\n",
       " array([0, 0, 0, ..., 1, 1, 1]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We drop useless columns\n",
    "df_final = df.drop(['Unnamed: 0', 'lat', 'lon', 'date'],axis=1)#'date','lat', 'lon'\n",
    "\n",
    "categories = np.unique(df_final[\"searching\"])\n",
    "\n",
    "columns = ['speed', 'double_cross', 'time_in_range', 'cluster_proximity']\n",
    "\n",
    "\n",
    "#We make sure to drop the column we’re predicting to prevent it from leaking \n",
    "#into the training set and the test set. \n",
    "#We must avoid using the same dataset to train and test the model.\n",
    "\n",
    "X = df_final.drop(['searching'],axis=1).values\n",
    "y = df_final['searching'].values\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We then split the data into a training and test set. We use 0.7 of the data for training and 0.3 for testing.\n",
    "\n",
    "#X_train represents the independent variables we’re using to train\n",
    "#y_train represents the column we’re predicting\n",
    "\n",
    "#X_test represents the independent variables we’re using to test\n",
    "#y_test represents the column we’re predicting during tests\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature scaling standardizes the range of our independent variables.\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we build the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use the add method to add different layers to our ANN.\n",
    "\n",
    "#We start with the first layer.\n",
    "\n",
    "#The first parameter is the number of nodes you want to add to this layer.\n",
    "#Common strategy: choose the number of nodes as the average of nodes in the input layer \n",
    "#and the number of nodes in the output layer. \n",
    "#In our case 4 independent variable in input, 1 output: 1+4=5/2=2.5=3\n",
    "\n",
    "#The second parameter, kernel_initializer, is the function that will be used to initialize the weights.\n",
    "#In this case, it will use a uniform distribution to make sure that the weights are small numbers close to zero\n",
    "\n",
    "#The next parameter is the activation function. \n",
    "#We use the Rectifier function, shortened as ReLU. We mostly use this function for the hidden layer in ANN.\n",
    "\n",
    "#The final parameter is input_dim, which is the number of nodes in the input layer. \n",
    "#It represents the number of independent variables. \n",
    "#In our case: 4\n",
    "\n",
    "classifier.add(\n",
    "        Dense(3, kernel_initializer = 'uniform',\n",
    "              activation = 'relu', input_dim=len(columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the second hidden layer\n",
    "#We don’t need to specify the input_dim parameter because we have already specified it in the first hidden layer\n",
    "\n",
    "classifier.add(\n",
    "      Dense(3, kernel_initializer = 'uniform',\n",
    "              activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the output hidden layer\n",
    "#We change the first parameter because in our output node we expect one node\n",
    "\n",
    "#We change the activation function because we want to get the probabilities that a claim is fraudulent. \n",
    "#We do this by using the Sigmoid activation function.\n",
    "\n",
    "classifier.add(\n",
    "     Dense(1, kernel_initializer = 'uniform',\n",
    "           activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the ANN\n",
    "\n",
    "#Compiling is basically applying a stochastic gradient descent to the whole neural network\n",
    "\n",
    "#The second parameter is the loss function within the stochastic gradient algorithm. \n",
    "#Since our categories are binary, we use the binary_crossentropy\n",
    "\n",
    "#The final argument is the criterion we’ll use to evaluate our model. \n",
    "#In this case we use the accuracy.\n",
    "\n",
    "classifier.compile(optimizer= 'adam',\n",
    "                  loss = 'binary_crossentropy',\n",
    "                  metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting our ANN to the training set\n",
    "\n",
    "#Epochs represents the number of times we’re going to pass our full dataset through the ANN.\n",
    "#Batch_size is the number of observations after which the weights will be updated.\n",
    "\n",
    "# Hyper-parameters\n",
    "BATCH_SIZE = 35\n",
    "EPOCHS = 30\n",
    "\n",
    "\n",
    "# fit model\n",
    "#history = classifier.fit(X_train, y_train, validation_split=0.3, batch_size=BATCH_SIZE,epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a single prediction\n",
    "\n",
    "#new_pred = classifier.predict(sc.transform(np.array([[a,b,c,d]])))\n",
    "\n",
    "#Where a,b,c,d represents our 4 features\n",
    "\n",
    "#new_pred = (new_prediction > 0.5)\n",
    "\n",
    "#NB: Since our classifier expects numpy arrays, \n",
    "#we have to transform the single observation into a numpy array and use the standard scaler to scale it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the ANN\n",
    "\n",
    "#After training the model one or two times, you’ll notice that you keep getting different accuracies\n",
    "\n",
    "#This introduces the bias variance trade off. \n",
    "#In essence, we’re trying to train a model that will be accurate \n",
    "#and not have too much variance of accuracy when trained several times.\n",
    "\n",
    "#We use the K-fold cross validation with K equal to 10. \n",
    "#This will split the training set into 10 folds. \n",
    "#We’ll then train our model on 9 folds and test it on the remaining fold.\n",
    "\n",
    "#We’re going to do this iteratively through 10 combinations. \n",
    "#Each iteration will gives us its accuracy. We’ll then find the mean of all accuracies.\n",
    "#We also calculate the variance to ensure that it’s minimal.\n",
    "\n",
    "#Keras has a scikit learn wrapper (KerasClassifier) that enables us \n",
    "#to include K-fold cross validation in our Keras code.\n",
    "\n",
    "#The KerasClassifier expects one of its arguments to be a function;\n",
    "#the purpose of this function is to build the architecture of our ANN.\n",
    "\n",
    "\n",
    "def make_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(3, kernel_initializer = 'uniform', activation = 'relu', input_dim=len(columns)))\n",
    "    classifier.add(Dense(3, kernel_initializer =  'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(1, kernel_initializer =  'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer= 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "#Here we wrap our previous ANN architecture in a function and return the classifier.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5964 - accuracy: 0.6494 - val_loss: 0.5774 - val_accuracy: 0.6436\n",
      "Epoch 2/30\n",
      "1153/1153 [==============================] - 2s 1ms/step - loss: 0.5727 - accuracy: 0.6494 - val_loss: 0.5769 - val_accuracy: 0.6436\n",
      "Epoch 3/30\n",
      "1153/1153 [==============================] - 2s 1ms/step - loss: 0.5727 - accuracy: 0.6485 - val_loss: 0.5769 - val_accuracy: 0.6436\n",
      "Epoch 4/30\n",
      "1153/1153 [==============================] - 2s 1ms/step - loss: 0.5725 - accuracy: 0.6479 - val_loss: 0.5768 - val_accuracy: 0.6436\n",
      "Epoch 5/30\n",
      "1153/1153 [==============================] - 2s 1ms/step - loss: 0.5720 - accuracy: 0.6494 - val_loss: 0.5761 - val_accuracy: 0.6436\n",
      "Epoch 6/30\n",
      "1153/1153 [==============================] - 2s 1ms/step - loss: 0.5689 - accuracy: 0.6716 - val_loss: 0.5712 - val_accuracy: 0.6766\n",
      "Epoch 7/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5649 - accuracy: 0.6833 - val_loss: 0.5674 - val_accuracy: 0.6826\n",
      "Epoch 8/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5623 - accuracy: 0.6872 - val_loss: 0.5656 - val_accuracy: 0.6847\n",
      "Epoch 9/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5611 - accuracy: 0.6907 - val_loss: 0.5648 - val_accuracy: 0.6861\n",
      "Epoch 10/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5602 - accuracy: 0.6919 - val_loss: 0.5639 - val_accuracy: 0.6872\n",
      "Epoch 11/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5596 - accuracy: 0.6918 - val_loss: 0.5641 - val_accuracy: 0.6885\n",
      "Epoch 12/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5591 - accuracy: 0.6914 - val_loss: 0.5629 - val_accuracy: 0.6880\n",
      "Epoch 13/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5587 - accuracy: 0.6927 - val_loss: 0.5627 - val_accuracy: 0.6865\n",
      "Epoch 14/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5583 - accuracy: 0.6918 - val_loss: 0.5629 - val_accuracy: 0.6884\n",
      "Epoch 15/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5582 - accuracy: 0.6932 - val_loss: 0.5624 - val_accuracy: 0.6880\n",
      "Epoch 16/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5580 - accuracy: 0.6924 - val_loss: 0.5623 - val_accuracy: 0.6881\n",
      "Epoch 17/30\n",
      "1153/1153 [==============================] - 2s 1ms/step - loss: 0.5578 - accuracy: 0.6929 - val_loss: 0.5621 - val_accuracy: 0.6889\n",
      "Epoch 18/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5577 - accuracy: 0.6915 - val_loss: 0.5623 - val_accuracy: 0.6872\n",
      "Epoch 19/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5575 - accuracy: 0.6915 - val_loss: 0.5617 - val_accuracy: 0.6877\n",
      "Epoch 20/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5573 - accuracy: 0.6919 - val_loss: 0.5615 - val_accuracy: 0.6880\n",
      "Epoch 21/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5572 - accuracy: 0.6922 - val_loss: 0.5614 - val_accuracy: 0.6877\n",
      "Epoch 22/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5568 - accuracy: 0.6924 - val_loss: 0.5609 - val_accuracy: 0.6885\n",
      "Epoch 23/30\n",
      "1153/1153 [==============================] - 2s 1ms/step - loss: 0.5567 - accuracy: 0.6930 - val_loss: 0.5615 - val_accuracy: 0.6876\n",
      "Epoch 24/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5565 - accuracy: 0.6926 - val_loss: 0.5607 - val_accuracy: 0.6889\n",
      "Epoch 25/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5564 - accuracy: 0.6930 - val_loss: 0.5604 - val_accuracy: 0.6875\n",
      "Epoch 26/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5563 - accuracy: 0.6930 - val_loss: 0.5610 - val_accuracy: 0.6882\n",
      "Epoch 27/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5561 - accuracy: 0.6940 - val_loss: 0.5603 - val_accuracy: 0.6885\n",
      "Epoch 28/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5561 - accuracy: 0.6925 - val_loss: 0.5609 - val_accuracy: 0.6891\n",
      "Epoch 29/30\n",
      "1153/1153 [==============================] - 2s 2ms/step - loss: 0.5560 - accuracy: 0.6918 - val_loss: 0.5599 - val_accuracy: 0.6905\n",
      "Epoch 30/30\n",
      "1153/1153 [==============================] - 2s 1ms/step - loss: 0.5558 - accuracy: 0.6935 - val_loss: 0.5599 - val_accuracy: 0.6902\n"
     ]
    }
   ],
   "source": [
    "#Create a new classifier using K-fold cross validation a\n",
    "#and pass the parameter build_fn as the function we just created above.\n",
    "\n",
    "classifier = KerasClassifier(build_fn = make_classifier,\n",
    "                            batch_size=BATCH_SIZE, nb_epoch=EPOCHS)\n",
    "\n",
    "#We train our classifier again\n",
    "history = classifier.fit(X_train, y_train, validation_split=0.3, batch_size = BATCH_SIZE, epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True]\n",
      " [False]\n",
      " [False]\n",
      " ...\n",
      " [ True]\n",
      " [False]\n",
      " [False]]\n"
     ]
    }
   ],
   "source": [
    "#Predicting using the training set\n",
    "\n",
    "#This will show us the probability of a searching status.\n",
    "#We then set a threshold of 50% for classifying a status as 'searching'.\n",
    "#Any status with a probability of 0.5 or more will be classified as 'searching'.\n",
    "\n",
    "y_pred = classifier.predict(X_test).astype(\"int32\")\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13765,  2221],\n",
       "       [ 5366,  3353]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEaCAYAAAAVJPDdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAz/klEQVR4nO3de3wU1f3/8ddeciUksEm4BWI1IAgWawwagoCYyK2oFLkUv6KAiopg0SoIingpFotc/AoIX41c1LZIUUERaQIKLReFnyIStCVcFLkngQBJNsnuzu+PJWuGBAgBNmR5Px+PPHZnzpmZ88km89mZM3PGYhiGgYiIyEnWmm6AiIhcWpQYRETERIlBRERMlBhERMREiUFEREyUGERExESJQaQK5s2bh91uP6dlnn/+eZo3b36RWiRy8SgxSK02ePBgLBYLffr0qVC2ZMkSLBbLOe/Q/emWW27hgQceqOlmiJgoMUitFx8fzyeffMLBgwdN8+fMmcMVV1xRQ60Sqb2UGKTWa9GiBcnJycybN88376effiIjI4MhQ4ZUqP/pp59yww03EBISQoMGDRg+fDgFBQW+co/Hw/jx42nQoAEREREMGDCAI0eOVFhPRkYGHTp0ICwsjLi4OIYMGUJubu4FjW3Dhg106tSJsLAw6tevz913382hQ4d85T///DN33XUXMTExhIaGctVVVzF58mRf+ZIlS7j++usJDw+nXr163HjjjXzzzTcXtI0SeJQYJCAMGzaMt956i7IRXt566y1SU1MrHDFs2bKFO+64g06dOvHtt98yf/58PvnkEx5++GFfnddff52pU6cyefJkvv76a2644QZeeOEF03pWrVrFnXfeye9//3u2bNnCRx99xO7du+nTpw8XapSZAwcO0LVrV5o2bcpXX33Fxx9/zNatW+nbt6+vzvDhw8nPzyczM5MffviB9PR0mjZt6lu+X79+DBw4kKysLNavX8+oUaMu6VNrcokwRGqx++67z0hNTTWKiooMh8NhrFq1ynC5XEZcXJyxePFiY+7cuYbNZvPVv+eee4x27dqZ1vHRRx8ZFovF2L17t2EYhhEXF2eMGzfOVOeuu+4yradz587GmDFjTHV+/PFHAzC++eYbwzAMY8KECUZCQsIZ29+5c2fj/vvvr7Ts2WefNeLi4ozi4mLfvM2bNxuAsXr1asMwDKNt27bGhAkTKl3+66+/NgBj165dZ2yDyKl0xCABITQ0lEGDBvHmm2+ybNkyXC4Xt99+e4V6WVlZdOrUyTSvc+fOGIbBtm3bOHbsGHv37iUlJcVU5+abbzZNb9y4kenTpxMREeH7ad26NQDbt2+/IDFlZWWRnJxMcHCwb951111HVFQUWVlZAIwaNYqXX36Zm266iTFjxrBmzRpf3bZt29KtWzeuvfZafve73/Haa6+xZ8+eC9I2CWw6ppSAMWzYMBITE9mzZw9DhgwhKCjoom3L4/EwZswYBg0aVKGsUaNGF227pxoyZAjdu3fns88+4/PPP6dHjx787ne/491338Vms7F8+XI2btxIZmYmixcv5umnn2bRokX06tXLb22U2kdHDBIwWrduTbt27Vi7du1pLwFt06aN6Vs1wOrVq7FYLLRp04bIyEji4uJYt26dqc7atWtN00lJSWRlZdG8efMKPxERERcknjZt2rBhwwZKSkp887799lvy8/O59tprffMaN27MkCFDWLBgAenp6bz33nscO3YMAIvFwo033si4ceNYs2YNnTt3Zu7cuRekfRK4dMQgAWXFihU4nU4cDkel5U899RSJiYk8/vjjPPTQQ+zevZuRI0fyP//zP8THxwPwxz/+kfHjx9OqVSuSk5NZunQpmZmZpvW8+OKLdO3alSeeeIJ7772XunXrsn37dhYtWsSMGTMICwurcpvz8vLYvHmzaV5kZCQjRozgtddeY/DgwYwbN46jR48yfPhwOnbsSMeOHQEYMWIEPXv2pGXLljidTj744AOaNWtG3bp1WbduHStXrqRr1640btyY7du3s2XLFu6///5z+I3KZammOzlEzkdZ5/PpnNr5bBiGsWzZMiMxMdEIDg42YmJijIcfftg4ceKEr9ztdhtjx441oqOjjfDwcOOuu+4ypk6dWmE9a9asMVJTU42IiAgjPDzcaNWqlfGHP/zBKC0tNQyj6p3PQIWfbt26GYZhGOvXrzc6duxohIaGGlFRUcbAgQONgwcP+pYfPny40aJFCyM0NNRwOBxGz549ja1btxqGYRhbt241evToYTRs2NAIDg424uPjjSeffNLUmS1SGYth6AluIiLyC/UxiIiIiRKDiIiYKDGIiIiJEoOIiJgoMYiIiEmtv49h3759575QURGNO3bEFRFB3ty5uK+88sI3rAbExMSQk5NT0824YAItHgi8mAItHgi8mCqLp0mTJmdc5vI8YggLwzVvHtacHGJ79SLklDthRUQuZ5dnYgCMW24h59NPcTdujON//oc6b74JuqVDROTyTQwA7vh4cpYswdmtG8FffaXEICJCAPQxnC+jTh2O/N//QUkJWK3Y9u7FCArC06BBTTdNRKRGXNZHDD5WK4SGgmFQ/5FHiO3Zk6Bvv63pVomI1IjL8ogh7IMPsL/3HtGGAXY7ht3ufQ0KwhMejv3oUWJ69aLkpptwJSR4EweAxWJ+BYxT55UrO6OgIIygIIzgYN97goN/mVf2vm5dSps3x9OkSdXXLSJyHi7LxGAEBUGdOlBYCCUlWAsLweXC4nKBy4UnNhbbwYOErF9P0ObNGOHh3v4Hw8BSvh/CMMw7a4+nig0wvNsrLfVuswo8deviatmS0pYtf3lt1QpPTMw5RC4icnaXZWJw3n47riFDyD3TtcolJUQ99xzBmzaRs3QpRng4Ddq3x/bTT6ZqRT16cOSttwBo+OtfY8vLM5UX3nUXR//3fwFo1KIFlpN9GYbVihEWRsHAgRx7+mkshYXEpqWBzeYtt9nAYqG4Y0dcrVoR9P33hKxeTdi2bd5EdpLb4cB1MllYf/1rQhwO3FdcgTs+HuMcngkgIlLmskwMVRIcTP6kSVhOnPAeMQDHR43Cevz4L1cvGQauX/3Kt8jxP/4RS1ERFo/He/Tg8eBq1cpXXvDww1BaCh4PFrcbXC5KEhMhJATDaqWkUydwucDt9h29lCQn47zzTqx791LnnXcqNNN9xRVYiosJe/99rPPmEV2+LCYGd3w8riuuwN2sme/VHReHJyoKo25dsOtPQETMav3zGKp15zO18+5Gy4kT2A4cwLp/P7b9+7EdOEDxzTdTmphI0JYtxAwYgOXkIx3LlF59NZaiImx793oT1ik8ERF4IiMxIiNNr2WJwwgLwwgOxggJ8Saw4GBvH0i5976yU34IDfW+Wqt3jUNt/IzOJtBiCrR4IPBiqs6dz/q6WIsYERG4mjeH5s0rlJW2bUvp4cPkbt+O/ccfsf34I/Zduyi6/XbcCQmELlmCY/jwCssVd+mCERaGfedO7NnZAN6jmZISLE6nuU+luu0OCjInDIvFm6RO9ttQ7gjLUm6exWqlYWioNzmFh/tePeXeG2Fh3lNmQUEYVqu3z8dq9f6cfG+ab7F4t1W2HcP4pS3lX8Fbv/zFCXa7dzs2m+kVm+2XixAqU67MUq8eIQUFv7TLav3l9GHZdNlP+d9Lufem35XH410uKOiX9lX2Wtb+U7dZ/vd18vSliI4YAsjZYrIUFWH78Udse/Zgy8nBevgwhQMH4omNJXTpUupOnYrt8GGsR4/6ljm4ejWeBg2ImDWLuq+/7ptvAEZICEdnzsQIDSV02TJC/v1v706y3E6mqGdPLC4XQdu2YSv7rMr6UGw2Stu0AYsF6+HDWAoKvMvZbBh2O8GhoTgjIrAUFmI7WW4pLobiYizlfwoLvclMLghfIgXva/mfk/OMk68Wmw3j5OeF3W5Olqe84vFgKS31XXhR6avLBYZhvjovJOSXq/ZOHqlSdrR68u+lLLEZp3kPeNdfUgKlpd4LP8rel5R4t3/yvS00FJfFYt5u2ZFy2dWCZV9wTp7ytbhc3uXLpsvH5XZ7fzflj6jDwio90iYoqOKVjuXfl3stuekmXFdffdbPU0cMckZGWBiuVq1M/R5lnHfcgfOOO7wTJSVYc3Kw5eTgjo+H4GCK7rwT15VXYiksxFpY6N0ZFxbi7NIFQkOxHj6M7dAh7z9bcbH3n624mBN//CNYrUS+9BLBmzb5duYAntBQcpYtA6DeyJGErVhhbm+DBuR/8w0A9YcOJWztWlO564orOHjyfpPo/v0JOaW8tFUrcj75BDweovv3J2jbtl+Sls1GyfXXey8csFhw3HMPtj17TJ3/JcnJHHvhBXC5cNx3H9bc3JMN836XKmnXjoL778fidhP11FPeuMrtRIuTkynq1w+AyGeeASAoKIjSk0mspF07im+9FYqLvUnXYsGwWCjbHZQkJVFy441YnE7C333X/A3fYqEkJYWSxESsR44Q/re//dK2k1fPlbRti7tZM6y5ud6kfcoVda6WLfHExmI5epSgLVu8y5X//SUkYERFYc3Px7Zjh3dHWP73f+WVhDocFO/bh23vXvORmMeDx+HwLlNQgDU/39v+kBCMOnXAZsPdoIH3/qGSEixFRb8c1QC4XBiRkeDxYM3P9/btle1snU4sx49jWK3eI6myHXvZkZTb7X1fdnTocmE5mWzKLks3goK8fYcnjzQNmw0jNBTsdmx2O0ZBAQDWEyewOJ3ebZRPKie3Z9jt3r+Zk+s1HVkGB/sSlKW4GEtenvkLTUkJOJ1Ync4K/49VcfTPf65SYqgOJQapKDgYT5Mm3nsnTnJdcw2ua6457SJF/ftT1L//acuPjR/PsfHjvROG4e1gLy31lee/8ALHn3rK909uKS2lXr16vvLjTzxB4T33mC4rNkJDfeUnHnjAe3Tidnu/obndeBwO35VZhf36Ydu3z7vsyR2HOz7ed2FBSVIStqZNvTsStxuL2427aVPf8q6EBKwOh/nCgxYtcLVuDZy8CKCw8JfTYB4P7qZNKb3uOm/9oCDfpcllOy5PbCwlHTpgKSrC+tJL5lNGhoEnOpri1FSsOTlEPv/8L6fZTm6/uEsXStu1w7Z7tzfplj8V5vHg7NGDogEDsG/dSuRf/uJbb1lf05F+/Si66y6C16+n7htvVPjMCh54AGe3boRkZBBdyYUPxx97jKDevSl+6y3qP/pohfLDy5ZR+pvfEP7ee9QbPbpC+aHVq3E1b06dOXOIevHFCuUHNm3C07gxEVOnEjllSoXy/T/8gFG3LpEvvkjEnDkVyvft2QNWK1GjR1PnvfdMZZ6wMA6cPHVab8QIwj/80FRuj43l4ObNADgGDyY0I8NU7vrVrzh08otIdN++hKxfbyovufZa35eemJ49CT7lhtni5GRyFy8GILZjR4J27vQdhWG14uzYkfzXXvMu36sX1sOHfzlasFpxpqZS1LdvhZgvFJ1KCiCBFlOgxQOXWExl9+GcTNSmPh/DgJPfeHG5vN/oy5VZDANPRAQxTZqQu2cP1rw8X0IuS6yu+HgIC/Meff74o/leIMOgtG1bjLAwrHv3Yt+1q0J5cXIyhIZi27ED+44dpv4nDANn164QFIR961Zz+cmfoj59wGIhaONG7Dt3mtZt2GwUDRgAQPCaNdh37/YtF1GnDsfdbop+/3sAQv75T+zl2o9hYERGUnj33QCEffSR9zRpucTtjo31rT9s4UJsBw6Yy5s08ZXXSU/3/v7Krd911VW+L1oR06b9cjVk2e+uTZszfhErrzqnkpQYAkigxRRo8UDgxRRo8UDgxaTnMYiIyHlTYhARERMlBhERMVFiEBEREyUGERExUWIQERETJQYRETFRYhARERMlBhERMVFiEBEREyUGERExUWIQERETJQYRETFRYhARERMlBhERMfHbE9w2b97M3Llz8Xg8pKam0rt3b1P5F198wTvvvIPD4QCge/fupKam+qt5IiJykl8Sg8fjIT09nWeffZbo6GjGjh1LUlISTZs2NdVLSUnh/vvv90eTRETkNPxyKik7O5tGjRrRsGFD7HY7KSkpbNy40R+bFhGRc+SXI4a8vDyio6N909HR0Wzfvr1CvS+//JLvv/+exo0bc9999xETE1OhTmZmJpmZmQBMmjSp0jpVYbfbq73spSrQYgq0eCDwYgq0eCDwYqpOPH7rYzibG264gQ4dOhAUFERGRgYzZ85kwoQJFeqlpaWRlpbmm67us1kD7bmuEHgxBVo8EHgxBVo8EHgxXbLPfHY4HOTm5vqmc3NzfZ3MZerWrUtQUBAAqamp7Ny50x9NExGRU/glMSQkJLB//34OHTqEy+Vi3bp1JCUlmeocOXLE937Tpk0VOqZFRMQ//HIqyWazMXToUCZOnIjH46FLly40a9aMhQsXkpCQQFJSEsuXL2fTpk3YbDYiIiIYPny4P5omIiKnsBiGYdR0I87Hvn37qrVcoJ1HhMCLKdDigcCLKdDigcCL6ZLtYxARkdpDiUFEREyUGERExESJQURETJQYRETERIlBRERMlBhERMREiUFEREyUGERExESJQURETJQYRETERIlBRERMlBhERMREiUFEREyUGERExESJQURETJQYRETERIlBRERMlBhERMREiUFEREyUGERExESJQURETJQYRETERIlBRERMlBhERMREiUFEREyUGERExMRviWHz5s384Q9/YOTIkXz00Uenrbdhwwb69+/Pjh07/NU0EREpxy+JwePxkJ6ezrhx45g2bRpr167l559/rlCvqKiI5cuX06JFC380S0REKuGXxJCdnU2jRo1o2LAhdrudlJQUNm7cWKHewoULufPOOwkKCvJHs0REpBJ2f2wkLy+P6Oho33R0dDTbt2831dm5cyc5OTkkJiaydOnS064rMzOTzMxMACZNmkRMTEy12mS326u97KUq0GIKtHgg8GIKtHgg8GKqTjx+SQxn4/F4WLBgAcOHDz9r3bS0NNLS0nzTOTk51dpmTExMtZe9VAVaTIEWDwReTIEWDwReTJXF06RJkzMu45fE4HA4yM3N9U3n5ubicDh8006nkz179vDCCy8AcPToUf7yl78wevRoEhIS/NFEERE5yS+JISEhgf3793Po0CEcDgfr1q3jscce85WHh4eTnp7um37++ecZNGiQkoKISA3wS2Kw2WwMHTqUiRMn4vF46NKlC82aNWPhwoUkJCSQlJTkj2aIiEgV+K2PITExkcTERNO8AQMGVFr3+eef90OLRESkMrrzWURETJQYRETERIlBRERMlBhERMREiUFEREyUGERExESJQURETJQYRETERIlBRERMlBhERMREiUFEREyUGERExESJQURETJQYRETERIlBRERMlBhERMREiUFEREyUGERExESJQURETJQYRETERIlBRERMlBhERMTEXtWKW7dupUGDBjRo0IAjR47w3nvvYbVaufvuu6lXr95FbKKIiPhTlY8Y0tPTsVq91RcsWIDb7cZisTBnzpyL1jgREfG/Kh8x5OXlERMTg9vt5ttvv2XWrFnY7XYeeuihi9k+ERHxsyonhrCwMI4ePcqePXto2rQpoaGhuFwuXC7XxWyfiIj4WZUTQ/fu3Rk7diwul4vBgwcD8MMPPxAXF3ex2iYiIjWgyomhd+/e3HjjjVitVho1agSAw+Hg4YcfvmiNExER/6tyYgBo0qSJ7/3WrVuxWq20bt26Sstu3ryZuXPn4vF4SE1NpXfv3qbyf/7zn6xYsQKr1UpoaCgPPfQQTZs2PZfmiYjIBVDlxDBhwgQGDhxIq1at+Oijj1i2bBlWq5Vu3brRp0+fMy7r8XhIT0/n2WefJTo6mrFjx5KUlGTa8d9888107doVgE2bNjF//nyeeeaZaoYlIiLVVeXLVffs2cPVV18NwMqVK5kwYQITJ04kIyPjrMtmZ2fTqFEjGjZsiN1uJyUlhY0bN5rqhIeH+947nU4sFktVmyYiIhdQlY8YDMMA4MCBAwC+b/sFBQVnXTYvL4/o6GjfdHR0NNu3b69Q77PPPmPZsmW4XC6ee+65SteVmZlJZmYmAJMmTSImJqaqIZjY7fZqL3upCrSYAi0eCLyYAi0eCLyYqhNPlRNDy5Ytefvttzly5Ajt2rUDvEmibt2659bKM+jevTvdu3fn3//+N4sXL2bEiBEV6qSlpZGWluabzsnJqda2YmJiqr3spSrQYgq0eCDwYgq0eCDwYqosnvL9xZWp8qmkRx99lPDwcK644gr69+8PwL59++jZs+dZl3U4HOTm5vqmc3NzcTgcp61f2akmERHxjyofMdStW5e7777bNC8xMbFKyyYkJLB//34OHTqEw+Fg3bp1PPbYY6Y6+/fvp3HjxgB8/fXXvvciIuJfVU4MLpeLDz74gDVr1nDkyBHq169Pp06d6NOnD3b7mVdjs9kYOnQoEydOxOPx0KVLF5o1a8bChQtJSEggKSmJzz77jO+++w6bzUZERASPPvroeQcnIiLnrsqJ4d1332XHjh08+OCDxMbGcvjwYRYvXkxhYaHvTugzSUxMrHCEMWDAAN/7IUOGVL3VIiJy0VQ5MWzYsIHJkyf7OpubNGnClVdeyVNPPVWlxCAiIrVDlTufyy5XFRGRwFblI4b27dvzyiuv0LdvX9/lT4sXL6Z9+/YXs30iIuJnVU4M99xzD4sXLyY9PZ0jR47gcDhISUnRsNsiIgGmyonBbrczYMAAU4dxSUkJgwYN4p577rkojRMREf+rch9DZTSekYhI4DmvxCAiIoHnrKeStm7detoy9S+IiASesyaGN95444zlgTQKoYiIVCExzJw50x/tEBGRS4T6GERExESJQURETJQYRETERIlBRERMlBhERMREiUFEREyUGERExESJQURETJQYRETERIlBRERMlBhERMREiUFEREyUGERExESJQURETJQYRETERIlBRERMlBhERMTkrE9wu1A2b97M3Llz8Xg8pKam0rt3b1P5J598wsqVK7HZbERGRvLII48QGxvrr+aJiMhJfjli8Hg8pKenM27cOKZNm8batWv5+eefTXV+9atfMWnSJF599VWSk5N59913/dE0ERE5hV8SQ3Z2No0aNaJhw4bY7XZSUlLYuHGjqc61115LSEgIAC1atCAvL88fTRMRkVP45VRSXl4e0dHRvuno6Gi2b99+2vqrVq3iN7/5TaVlmZmZZGZmAjBp0iRiYmKq1Sa73V7tZS9VgRZToMUDgRdToMUDgRdTdeLxWx9DVa1Zs4adO3fy/PPPV1qelpZGWlqabzonJ6da24mJian2speqQIsp0OKBwIsp0OKBwIupsniaNGlyxmX8cirJ4XCQm5vrm87NzcXhcFSot2XLFj788ENGjx5NUFCQP5omIiKn8EtiSEhIYP/+/Rw6dAiXy8W6detISkoy1dm1axdvvvkmo0ePJioqyh/NEhGRSvjlVJLNZmPo0KFMnDgRj8dDly5daNasGQsXLiQhIYGkpCTeffddnE4nU6dOBbyHP2PGjPFH80REpBy/9TEkJiaSmJhomjdgwADf+/Hjx/urKSIicga681lEREyUGERExESJQURETJQYRETERIlBRERMlBhERMREiUFEREyUGERExESJQURETJQYRETERIlBRERMlBhERMREiUFEREyUGERExESJQURETJQYRETERIlBRERMlBhERMREiUFEREyUGERExESJQURETJQYRETERIlBRERMlBhERMREiUFEREyUGERExESJQURETOz+2tDmzZuZO3cuHo+H1NRUevfubSrftm0b8+fP58cff2TUqFEkJyf7q2kiIlKOX44YPB4P6enpjBs3jmnTprF27Vp+/vlnU52YmBiGDx/OzTff7I8miYjIafjliCE7O5tGjRrRsGFDAFJSUti4cSNNmzb11WnQoAEAFovlvLZlGAZOpxOPx3PGdR08eJDi4uLz2talJtBiqul4DMPAarUSGhp63n+XIrWJXxJDXl4e0dHRvuno6Gi2b99erXVlZmaSmZkJwKRJk4iJiTGV5+bmEhoaSlBQ0FnXFRISUq02XMoCLaaajqe0tBSr1Wr6+z0fdru9wt9sbRZo8UDgxVSdePzWx3ChpKWlkZaW5pvOyckxlRcUFFCnTh1cLtcZ12O3289ap7YJtJguhXgsFgsnTpzAMIwLsr6YmJgKf7O1WaDFA4EXU2XxNGnS5IzL+KWPweFwkJub65vOzc3F4XBclG3pkF8uNP1NyeXGL4khISGB/fv3c+jQIVwuF+vWrSMpKckfmxYRkXPkl8Rgs9kYOnQoEydO5PHHH6d9+/Y0a9aMhQsXsmnTJsDbQf3www+zYcMG/u///o8nnnjCH027KFq0aFFj205PT6dz586MGDHCNH/r1q2sXLnynNd34MABHnzwwbPWGzRoEPn5+ee8/rMZNWoUn3zyyRnrLFy4kAMHDlzwbYtcrvzWx5CYmEhiYqJp3oABA3zvmzdvzuzZs/3VnIA1f/58/v73v1c4h5iVlcWWLVtITU2tsIzL5cJur/xPoVGjRrz55ptn3e4777xTvQZfAIsWLaJVq1Y0atSoxtogEkhqXefzuYru27fCvKJevSh54AEsRUU4Bg2qUF7Yrx9FAwZgzcuj/rBhprLcf/yjWu3YunUrTz/9NE6nkyuuuIIpU6ZQr1490tPTeeedd7Db7bRo0YI33niD9evX89xzzwHe89sffPABERERpvXNmTOHhQsXAjBw4EAefPBBnnrqKX766ScGDRrEgAEDGHay7SUlJbz66qs4nU6++uorRowYQXZ2Nrt37+ann34iLi6OsWPH8thjj1FYWAjAn/70J9q1a8eePXu47777WLVqFQsXLiQjI4OioiJ2795Njx49ePbZZwG46aabWL58OQUFBdxzzz3ceOONbNq0iUaNGvH2228TFhbG5s2befLJJ7FYLHTq1InPP/+cVatWmeIyDINnn32WNWvWEBcXZ7q6bNq0aWRkZOB0OklKSuKVV15h2bJlfPvtt4wYMYLQ0FCWLl3K7NmzK9RTP4FI1WlIDD8ZNWoUzzzzDJmZmbRq1YqpU6cCMHPmTFasWEFmZiaTJk0CYPbs2bz88stkZGTw4YcfEhoaalrXli1beP/99/nkk0/4+OOP+etf/8rWrVuZPHkyDRs2ZNGiRb6kABAcHMyTTz7JHXfcQUZGBnfeeScA27dv5+9//zuzZs0iJiaGv/3tb6xYsYI33njDl5hOlZWVxRtvvMHKlStZunQpe/furVBn165d3HfffXz++edERkby6aefAvDEE08wadIkMjIysNlsla5/+fLl7Nixgy+++IIZM2b4TjUCDB48mE8//ZRVq1ZRVFRERkYGvXr14rrrrmPGjBlkZGQQFhZWaT0RqbqAP2I43Td8O2CEhZ3xCMDjcFT7CKG8Y8eOkZ+fT/v27QHo168fDz30EADXXHMNI0aMoHv37nTv3h2Adu3a8cILL/C73/2OHj16VDgt9NVXX9G9e3fCw8MB6NGjB19++SW/+c1vzqldXbt2JSwsDPBer//MM8+wbds2rFYrO3furHSZm2++mcjISACuvvpq9u7dS1xcnKlOs2bNuPbaawFo27Yte/bsIT8/nxMnTvguOujdu7fvfpTyNmzYQO/evbHZbDRq1IgOHTr4ytatW8cbb7xBUVERR48epWXLlnTt2rXCOqpaT0QqpyOGGrZgwQIGDx7Md999R8+ePXG5XIwYMYLJkyfjdDrp3bs32dnZF2XbZYkF4M033yQ2NpaMjAyWL19OaWlppcsEBwf73lut1krvMyh/U5rNZsPtdp93W51OJ+PGjWPOnDmsXLmSu+++u9K7oqtaT0ROT4nBDyIjI4mKiuLLL78EYPHixSQnJ+PxeNi3bx8dOnTgmWee4fjx4xQUFLB7926uueYaHn30Ua677roKieGmm25ixYoVFBUVUVhYyGeffcZNN910xjZERERw4sSJ05YfO3aMBg0aYLVaWbx48QXZmZcXFRVFREQEX3/9NQBLliyptF5ycjJLly7F7XZz8OBB1q1bB+DbuTscDgoKCli2bJlvmTp16vhiO1M9EamagD+VVBOKioq44YYbfNPDhg1j+vTpvs7n+Ph4pk6ditvtZuTIkRw/fhzDMBg6dChRUVFMnjyZdevWYbVaufrqq+nSpYtp/b/+9a/p168fv/3tbwFv53PZqZvTSUlJYebMmdx2220VLmUFuO+++xg2bBj/+Mc/6NKli+lo4kJ59dVXGT16NBaLhfbt21O3bt0KdXr06MHatWu55ZZbaNq0qe/3GBUVxd13301qaiqxsbFcd911vmX69+/P008/7et8Pl09Eakai3Gh7vWvIfv27TNNFxYWVmmndikMt3ChXeoxlQ1XAjBjxgwOHTrEiy++eNr6l0o8Vf2bqorLYbiF2i7QYqrOkBg6YhC/yczMZMaMGbjdbuLi4pg+fXpNN0lEKqHEIH5z5513+i6VFZFLlzqfRUTERIlBRERMlBhERMREiUFEREyUGC6CS3HY7XO1bt067r33XgD++c9/MmPGjErrnS3W/Px85s2b55uu6jDe56p8e0+nukOPi1xulBgCzPz58/nb3/522h15dXTt2rXaiebYsWMsWLDAN13VYbwvhqysrAqjuYpIRQF9uWrkc88RtG1bpWUWi6Vaz/Etbd2aY2e4Ket0anLYbYBevXoxZcoUWrZsCUDfvn0ZP348Ho+H5557juLiYkJDQ5k6dSrNmzc3bWvhwoVs2bKFiRMn8tNPP/Hoo49SWFhoGpiuoKCAIUOGkJ+fj8vlYvTo0XTr1o2XX36ZH3/8kdtuu41OnToxePBg3zDeTqeTsWPHsmXLFmw2GxMmTKBDhw6+4b2dTie7du0yDe9d3ueff86ECRMICwvjxhtv9M3/5ptvKsQUHx9fYejx+Pj4s8YucjkK6MRwKRk1ahQvvfQS7du3Z/LkyUydOpUXX3yRmTNnsn79ekJCQnxPQCsbdrtdu3YUFBSYBqUD87DbhmHQq1cv33pXrVrFokWLKjxT+4477uDjjz+mZcuWHDx4kIMHD3Lddddx/PhxPvzwQ+x2O2vWrOGVV1454zf65557jnvvvZd+/fqZThGFhISQnp5O3bp1ycvL4/bbb6dr166MGzeO//znP76hr/fs2eNbZt68eVgsFlauXEl2djYDBw7kX//6F+D9dr9y5UqsViudOnViyJAhplFcnU4nTz31FO+//z5XXnklDz/8sK+sefPmlcb05JNP+hIccM6xi1wuAjoxnOmbvT+HW7gUht2+/fbbufvuu3nyySf5+OOPfeMsHTt2jFGjRrFr1y4sFstpR1Uts3HjRt/O86677vLtZA3DYNKkSXz55ZdYLBYOHDjA4cOHz7quIUOGAN6dedOmTX3DfZcN7+1yuSod3js7O5v4+HiuuuoqX1vefffdc4rpXGMXuVyoj6GG+WvY7caNG1O/fn22bdvG0qVLueOOOwCYPHkyKSkprFq1innz5lVpiOrKnob2wQcfkJuby/Lly8nIyCAmJua8hruuyvDep1PVmKoTu8jlQInBDy6FYbfBezrpjTfe4Pjx47Ru3Rrwnk4pe1by+++/f9Z1tGvXzjdk9gcffOCbf/z4cWJiYggKCmLt2rX8/PPPgHlI7FPdeOONfPjhhwDs2LGDvXv3kpCQcNY2gPcIY8+ePezevRuAjz76yNSWymI6dejxc41d5HKhxHARlA27XfYzZ84cpk+fzksvvURaWhpZWVk8/vjjvmG3U1NT6datm2/Y7bfeeotbb72VtLQ0goKCzjjsdq9evao07DbAb3/7W5YsWcLtt9/um/fII4/w5z//ma5du1bpW/mLL77IvHnzSE1N5cCBA775ffr04dtvvyU1NZV//OMfvk5ch8NBu3btuPXWW3nppZdM67rvvvvweDykpqbyyCOPMG3atAr9KacTGhrKX/7yF+699166detGTEzMWWNKSUlh+/bt3HbbbSxZsuScYxe5XGjY7QASaDFdKvFo2O3TC7R4IPBiqs6w2zpiEBEREyUGERExCbjEUMvPjMklSH9TcrkJuMRwrpc2ipyJy+XCag24fxORMwq4G9xCQ0NxOp0UFxdXer19mZCQkIC7bj3QYqrpeAzDwGq1EhoaWmNtEKkJAZcYLBYLYWFhZ60XaFceQODFFGjxiNQWfksMmzdvZu7cub7r1nv37m0qLy0tZcaMGezcuZO6desyatQoGjRo4K/miYjISX45eerxeEhPT2fcuHFMmzbNdGdsmVWrVlGnTh1ef/11fvvb3/Lee+/5o2kiInIKvySG7OxsGjVqRMOGDbHb7aSkpLBx40ZTnU2bNnHLLbcAkJyczNatW3U1iIhIDfDLqaS8vDyio6N909HR0Wzfvv20dWw2G+Hh4Rw/fpzIyEhTvczMTDIzMwGYNGnSWe/gO5PzWfZSFWgxBVo8EHgxBVo8EHgxnWs8te46vLS0NCZNmsSkSZPOaz1PP/30BWrRpSPQYgq0eCDwYgq0eCDwYqpOPH5JDA6Hg9zcXN90bm5uhQfJlK/jdrspLCykbt26/mieiIiU45fEkJCQwP79+zl06BAul4t169aRlJRkqnPDDTfwxRdfALBhwwbatGlzxvsQRETk4vBLH4PNZmPo0KFMnDgRj8dDly5daNasGQsXLiQhIYGkpCRuvfVWZsyYwciRI4mIiGDUqFEXtU1paWkXdf01IdBiCrR4IPBiCrR4IPBiqk48tX7YbRERubBqXeeziIhcXEoMIiJiEnBjJVXF2YbnqG0effRRQkNDsVqt2Gy2876UtybMmjWLr7/+mqioKKZMmQLAiRMnmDZtGocPHyY2NpbHH3+ciIiIGm5p1VQWz/vvv8/KlSt99+YMHDiQxMTEmmzmOcnJyWHmzJkcPXoUi8VCWloaPXv2rLWf0+niqc2fU0lJCRMmTMDlcuF2u0lOTqZ///4cOnSI6dOnc/z4ca666ipGjhyJ3X6G3b9xmXG73caIESOMAwcOGKWlpcaTTz5p7Nmzp6abdV6GDx9u5Ofn13QzzktWVpaxY8cO44knnvDNe+edd4wPP/zQMAzD+PDDD4133nmnhlp37iqLZ+HChcaSJUtqsFXnJy8vz9ixY4dhGIZRWFhoPPbYY8aePXtq7ed0unhq8+fk8XiMoqIiwzAMo7S01Bg7dqzxn//8x5gyZYrx73//2zAMw5gzZ46xYsWKM67nsjuVVJXhOcT/WrduXeFb5saNG+ncuTMAnTt3rlWfU2Xx1Hb169fnqquuAiAsLIy4uDjy8vJq7ed0unhqM4vF4hsm3u1243a7sVgsZGVlkZycDMAtt9xy1s/osjuVVJXhOWqjiRMnAnDbbbcFzOV2+fn51K9fH4B69eqRn59fwy06fytWrGDNmjVcddVV3HvvvbU2eRw6dIhdu3bRvHnzgPicysfzww8/1OrPyePxMGbMGA4cOEC3bt1o2LAh4eHh2Gw2wHsz8dkS4GWXGALRSy+9hMPhID8/nz/96U80adKE1q1b13SzLiiLxVLrb3js2rUrffv2BWDhwoUsWLCA4cOH13Crzp3T6WTKlCkMHjyY8PBwU1lt/JxOjae2f05Wq5XJkydTUFDAq6++yr59+859HRehXZe0qgzPUduUtT8qKop27dqRnZ1dwy26MKKiojhy5AgAR44cqTCgYm1Tr149rFYrVquV1NRUduzYUdNNOmcul4spU6bQsWNHbrrpJqB2f06VxRMInxNAnTp1aNOmDf/9738pLCzE7XYD3rMmZ9vnXXaJoSrDc9QmTqeToqIi3/stW7YQHx9fw626MJKSkli9ejUAq1evpl27djXcovNTtvME+Oqrr2jWrFkNtubcGYbB7NmziYuLo1evXr75tfVzOl08tflzOnbsGAUFBYD3CqUtW7YQFxdHmzZt2LBhAwBffPHFWfd5l+Wdz19//TXz58/3Dc/Rp0+fmm5StR08eJBXX30V8HY23XzzzbUynunTp7Nt2zaOHz9OVFQU/fv3p127dkybNo2cnJxadRkkVB5PVlYWu3fvxmKxEBsby7Bhw3zn5muDH374geeee474+Hjf6aKBAwfSokWLWvk5nS6etWvX1trP6ccff2TmzJl4PB4Mw6B9+/b07duXgwcPMn36dE6cOMGVV17JyJEjCQoKOu16LsvEICIip3fZnUoSEZEzU2IQERETJQYRETFRYhARERMlBhERMVFikMvOyy+/7HuM7IWse6n74osvGD9+fE03Q2oBDYkhtcKgQYN870tKSrDb7Vit3u81w4YNo2PHjlVe17hx4y5K3XORlZXFiy++SHBwsGn++PHjufrqqy/KNkWqSolBaoV33nnH9/7RRx/loYceom3bthXqud1u32Bhl7r69esze/bsmm6GSAVKDFKrZWVl8frrr9O9e3eWLVtG27ZtGTJkCDNmzGD79u14PB5atmzJgw8+6BtV9/nnn6djx46kpqbyxRdfsHLlSlq0aMHnn39OeHg4DzzwANdff/051z106BAzZ85k165dtGjRgsaNG1NYWMhjjz12znE9//zzXH311Xz33Xfs27ePNm3aMHz4cN8dxZs2beKvf/0reXl5/OpXv+KBBx6gadOmgPcBNPPmzeP777/HMAw6dOjA/fff71v3ggULKm2/SBn1MUitd/ToUU6cOMGsWbN46KGHMAyDW265hVmzZjFr1iyCg4NJT08/7fLZ2dk0adKE9PR07rzzTmbPns3pBgQ4U93XXnuNhIQE3n77bfr168e//vWv84pr9erVPPLII8yZMwer1crbb78NwL59+3jttdcYPHgwb731Ftdffz2vvPIKLpcLj8fDK6+8QkxMDDNnzmT27Nl06NChWrHK5UuJQWo9i8VC//79CQoKIjg4mLp165KcnExISAhhYWH06dOH77///rTLx8TEkJaWhtVqpXPnzhw5cuS0zxQ4Xd2cnBx27NjBgAEDsNvttGrVihtuuOGM7T5y5AiDBw82/TidTl95p06diI+PJzQ0lN///vesX78ej8fDunXruP7662nbti12u53bb7+dkpIS/vOf/5CdnU1eXh6DBg0iNDSU4OBgWrVqVa1Y5fKlU0lS60VGRpo6cYuLi5k/fz6bN2/2jTRZVFSEx+PxdViXV69ePd/7kJAQANMOuip1jx07RkREhG8eeHfCOTk5p2332foYyj9QKiYmBrfbzbFjxzhy5AixsbG+MqvVSkxMDHl5edhsNmJjY0/bz3IuscrlS4lBar1THwzz8ccfs2/fPl5++WXq1avH7t27GT169EU9ZVK/fn1OnDhBcXGxb4d7pqRQFeWfG5KTk4PNZiMyMpL69evz008/+coMwyAnJweHw0FQUBA5OTm1qhNeLj06lSQBx+l0EhwcTHh4OCdOnGDRokUXfZuxsbEkJCSwaNEiXC4X//3vf/l//+//ndc6//Wvf/Hzzz9TXFzM+++/T3JyMlarlZSUFL755hu+++47XC4XH3/8MUFBQbRs2ZLmzZtTv3593nvvPZxOJyUlJfzwww8XKEq5XOiIQQJOz549+d///V/uv/9+HA4HvXr18ssD6keOHMmsWbMYOnQozZs3JyUlBY/Hc9r6R44cMd2fAd5Lccse2t6pUydmzpzJvn37uOaaa3yPl2zSpAkjR47k7bff9l2VNGbMGOx277/zmDFjePvttxk+fDgWi4UOHTqY+hlEzkbPYxC5SKZNm0ZcXBz9+/c/52XLXyYr4m86lSRygWRnZ3PgwAE8Hg+bN29m06ZNteYxlyLl6VSSyAVy9OhRpkyZwvHjx4mOjuaBBx7gyiuvrOlmiZwznUoSERETnUoSERETJQYRETFRYhARERMlBhERMVFiEBERk/8P+MWeJKDwGrgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy and loss\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['accuracy'], \"g--\", label=\"Accuracy of training data\")\n",
    "plt.plot(history.history['val_accuracy'], \"g\", label=\"Accuracy of validation data\")\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Training Epoch')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0,1])\n",
    "plt.ylim(0)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# summarize history for accuracy and loss\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], \"r--\", label=\"Loss of training data\")\n",
    "plt.plot(history.history['val_loss'], \"r\", label=\"Loss of validation data\")\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.ylim(0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65255857, 0.63937557, 0.69210756, 0.66394866, 0.68528801,\n",
       "       0.68459404, 0.64555866, 0.65405971, 0.6384455 , 0.63827205])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This function will return the ten accuracies of the ten test folds used in the computation.\n",
    "\n",
    "#n_jobs=-1 will make use of all available CPUs. \n",
    "#cv is the number of folds and 10 is a typical choice.\n",
    "\n",
    "accuracies = cross_val_score(estimator = classifier,\n",
    "                             X = X_train,\n",
    "                             y = y_train,\n",
    "                             cv = 10,\n",
    "                             n_jobs = -1)\n",
    "\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6594208300113678, 0.00039487651477049474)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To obtain the relative accuracies we get the mean of the accuracies.\n",
    "\n",
    "mean = accuracies.mean()\n",
    "\n",
    "#Then the variance.\n",
    "\n",
    "variance = accuracies.var()\n",
    "\n",
    "#Goal: to have a small variance between the accuracies.\n",
    "\n",
    "mean, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fighting Overfitting\n",
    "\n",
    "#Overfitting in machine learning is what happens when a model learns the details and noise in the training set \n",
    "#such that it performs poorly on the test set -> it happens  when we have huge differences between \n",
    "#the accuracies of the test set and training set, \n",
    "#or when you observe a high variance when applying k-fold cross validation.\n",
    "\n",
    "#In ANN, we counteract this using the Dropout Regularization technique, which works by randomly disabling \n",
    "#some neurons at each iteration of the training \n",
    "#to prevent them from being too dependent on each other.\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(3, kernel_initializer = 'uniform', activation = 'relu', input_dim=len(columns)))\n",
    "\n",
    "# Notice the dropouts\n",
    "classifier.add(Dropout(rate = 0.1))\n",
    "classifier.add(Dense(6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(rate = 0.1))\n",
    "\n",
    "#We used dropout after the first hidden layer and after the second hidden layer\n",
    "#Rate of 0.1 means that 1% of the neurons will be disabled at each iteration. \n",
    "#It should be always between 0.1 and 0.4 (to avoid underfitting)\n",
    "\n",
    "classifier.add(Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "classifier.compile(optimizer= 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter Tuning\n",
    "\n",
    "#Tune the parameters to get a higher accuracy\n",
    "\n",
    "#Modify our make_classifier\n",
    "#Create a new variable called optimizer \n",
    "#that will allow us to add more than one optimizer in our params variable\n",
    "#(earlier we were using only the Adam algorithm)\n",
    "\n",
    "def make_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(3, kernel_initializer = 'uniform', activation = 'relu', input_dim=len(columns)))\n",
    "    classifier.add(Dense(3, kernel_initializer =  'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(1, kernel_initializer =  'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer= optimizer,loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
    "    return classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We’ll still use the KerasClassifier, \n",
    "#but we won’t pass the batch size and number of epochs \n",
    "#since these are the parameters we want to tune.\n",
    "\n",
    "classifier = KerasClassifier(build_fn = make_classifier)\n",
    "\n",
    "#Create a dictionary with the parameters we’d like to tune \n",
    "\n",
    "params = {\n",
    "    'batch_size':[20,35],\n",
    "    'nb_epoch':[150,500],\n",
    "    'optimizer':['adam','rmsprop']\n",
    "}\n",
    "\n",
    "#We then use Grid Search to test these parameters.\n",
    "#It expects our estimator, the parameters we just defined, the scoring metric and the number of k-folds.\n",
    "\n",
    "grid_search = GridSearchCV(estimator=classifier,\n",
    "                           param_grid=params,\n",
    "                           scoring='accuracy',\n",
    "                           cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2405/2405 [==============================] - 2s 1ms/step - loss: 0.5895 - accuracy: 0.6650\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "2405/2405 [==============================] - 4s 1ms/step - loss: 0.6590 - accuracy: 0.6398\n",
      "2405/2405 [==============================] - 3s 1ms/step - loss: 0.5903 - accuracy: 0.6403\n",
      "2405/2405 [==============================] - 2s 1ms/step - loss: 0.6340 - accuracy: 0.6553\n",
      "2405/2405 [==============================] - 2s 1ms/step - loss: 0.5892 - accuracy: 0.6397\n",
      "2405/2405 [==============================] - 2s 979us/step - loss: 0.5887 - accuracy: 0.6404\n",
      "2405/2405 [==============================] - 2s 997us/step - loss: 0.5892 - accuracy: 0.6395\n",
      "2405/2405 [==============================] - 2s 998us/step - loss: 0.5889 - accuracy: 0.6417\n",
      "2405/2405 [==============================] - 2s 1ms/step - loss: 0.6324 - accuracy: 0.6537\n",
      "2405/2405 [==============================] - 2s 1ms/step - loss: 0.5888 - accuracy: 0.6662\n",
      "2405/2405 [==============================] - 3s 1ms/step - loss: 0.5925 - accuracy: 0.6428\n",
      "2405/2405 [==============================] - 2s 1ms/step - loss: 0.5946 - accuracy: 0.6583\n",
      "2405/2405 [==============================] - 2s 1ms/step - loss: 0.5917 - accuracy: 0.6572\n",
      "2405/2405 [==============================] - 2s 1ms/step - loss: 0.6383 - accuracy: 0.6530\n",
      "2405/2405 [==============================] - 2s 1ms/step - loss: 0.6202 - accuracy: 0.6554\n",
      "2405/2405 [==============================] - 3s 1ms/step - loss: 0.6581 - accuracy: 0.6404\n",
      "2405/2405 [==============================] - 3s 1ms/step - loss: 0.5945 - accuracy: 0.6593\n",
      "2405/2405 [==============================] - 2s 1ms/step - loss: 0.5949 - accuracy: 0.6599\n",
      "2405/2405 [==============================] - 3s 1ms/step - loss: 0.5983 - accuracy: 0.6424\n",
      "2405/2405 [==============================] - 2s 1ms/step - loss: 0.5986 - accuracy: 0.6406\n",
      "2405/2405 [==============================] - 3s 1ms/step - loss: 0.6294 - accuracy: 0.6574\n",
      "2405/2405 [==============================] - 2s 1ms/step - loss: 0.6312 - accuracy: 0.6561\n",
      "2405/2405 [==============================] - 3s 1ms/step - loss: 0.5844 - accuracy: 0.6701\n",
      "2405/2405 [==============================] - 3s 1ms/step - loss: 0.5918 - accuracy: 0.6413: 0s - loss: 0.5942 - accura\n",
      "2405/2405 [==============================] - 2s 1ms/step - loss: 0.5901 - accuracy: 0.6660\n",
      "2405/2405 [==============================] - 3s 1ms/step - loss: 0.6278 - accuracy: 0.6639\n",
      "2405/2405 [==============================] - 3s 1ms/step - loss: 0.5891 - accuracy: 0.6406\n",
      "2405/2405 [==============================] - 3s 1ms/step - loss: 0.5890 - accuracy: 0.6378\n",
      "2405/2405 [==============================] - 3s 1ms/step - loss: 0.5867 - accuracy: 0.6669\n",
      "2405/2405 [==============================] - 2s 1ms/step - loss: 0.5855 - accuracy: 0.6682\n",
      "2405/2405 [==============================] - 2s 1ms/step - loss: 0.6016 - accuracy: 0.6562\n",
      "2405/2405 [==============================] - 3s 1ms/step - loss: 0.6369 - accuracy: 0.6524\n",
      "2405/2405 [==============================] - 3s 1ms/step - loss: 0.5910 - accuracy: 0.6653\n",
      "2405/2405 [==============================] - 3s 1ms/step - loss: 0.5984 - accuracy: 0.6393\n",
      "2405/2405 [==============================] - 3s 1ms/step - loss: 0.5965 - accuracy: 0.6409\n",
      "2405/2405 [==============================] - 3s 1ms/step - loss: 0.6364 - accuracy: 0.6541\n",
      "2405/2405 [==============================] - 3s 1ms/step - loss: 0.5956 - accuracy: 0.6408\n",
      "2405/2405 [==============================] - 2s 1ms/step - loss: 0.5973 - accuracy: 0.6451\n",
      "2405/2405 [==============================] - 3s 1ms/step - loss: 0.5974 - accuracy: 0.6392\n",
      "2405/2405 [==============================] - 3s 1ms/step - loss: 0.5997 - accuracy: 0.6405\n",
      "1374/1374 [==============================] - 1s 1ms/step - loss: 0.6056 - accuracy: 0.6536\n",
      "1374/1374 [==============================] - 1s 1ms/step - loss: 0.6427 - accuracy: 0.6549\n",
      "1374/1374 [==============================] - 2s 1ms/step - loss: 0.6019 - accuracy: 0.6418: 0s - loss: 0.608\n",
      "1374/1374 [==============================] - 2s 1ms/step - loss: 0.6034 - accuracy: 0.6411\n",
      "1374/1374 [==============================] - 2s 1ms/step - loss: 0.6610 - accuracy: 0.6407\n",
      "1374/1374 [==============================] - 2s 1ms/step - loss: 0.5980 - accuracy: 0.6576\n",
      "1374/1374 [==============================] - 2s 1ms/step - loss: 0.6024 - accuracy: 0.6411\n",
      "1374/1374 [==============================] - 1s 1000us/step - loss: 0.5965 - accuracy: 0.6402\n",
      "1374/1374 [==============================] - 2s 1ms/step - loss: 0.6054 - accuracy: 0.6399\n",
      "1374/1374 [==============================] - 1s 1ms/step - loss: 0.6065 - accuracy: 0.6579\n",
      "1374/1374 [==============================] - 1s 999us/step - loss: 0.6299 - accuracy: 0.6482\n",
      "1374/1374 [==============================] - 1s 987us/step - loss: 0.6055 - accuracy: 0.6396\n",
      "1374/1374 [==============================] - 1s 1ms/step - loss: 0.6599 - accuracy: 0.6415\n",
      "1374/1374 [==============================] - 1s 1ms/step - loss: 0.6066 - accuracy: 0.6582\n",
      "1374/1374 [==============================] - 1s 1ms/step - loss: 0.6602 - accuracy: 0.6409\n",
      "1374/1374 [==============================] - 1s 1ms/step - loss: 0.6021 - accuracy: 0.6404\n",
      "1374/1374 [==============================] - 1s 983us/step - loss: 0.6048 - accuracy: 0.6552\n",
      "1374/1374 [==============================] - 2s 1ms/step - loss: 0.6028 - accuracy: 0.6407\n",
      "1374/1374 [==============================] - 3s 2ms/step - loss: 0.6455 - accuracy: 0.6502\n",
      "1374/1374 [==============================] - 2s 2ms/step - loss: 0.6470 - accuracy: 0.6478\n",
      "1374/1374 [==============================] - 2s 1ms/step - loss: 0.6046 - accuracy: 0.6403\n",
      "1374/1374 [==============================] - 2s 1ms/step - loss: 0.6085 - accuracy: 0.6395\n",
      "1374/1374 [==============================] - 2s 1ms/step - loss: 0.6057 - accuracy: 0.6415\n",
      "1374/1374 [==============================] - 2s 1ms/step - loss: 0.5967 - accuracy: 0.6418\n",
      "1374/1374 [==============================] - 1s 1ms/step - loss: 0.6455 - accuracy: 0.6546\n",
      "1374/1374 [==============================] - 2s 1ms/step - loss: 0.6609 - accuracy: 0.6405\n",
      "1374/1374 [==============================] - 2s 1ms/step - loss: 0.5981 - accuracy: 0.6411\n",
      "1374/1374 [==============================] - 2s 2ms/step - loss: 0.6424 - accuracy: 0.6546\n",
      "1374/1374 [==============================] - 2s 1ms/step - loss: 0.6456 - accuracy: 0.6520\n",
      "1374/1374 [==============================] - 2s 1ms/step - loss: 0.5970 - accuracy: 0.6598\n",
      "1374/1374 [==============================] - 3s 2ms/step - loss: 0.6087 - accuracy: 0.6523\n",
      "1374/1374 [==============================] - 2s 1ms/step - loss: 0.6111 - accuracy: 0.6466\n",
      "1374/1374 [==============================] - 2s 1ms/step - loss: 0.6099 - accuracy: 0.6417\n",
      "1374/1374 [==============================] - 1s 1ms/step - loss: 0.6115 - accuracy: 0.6522\n",
      "1374/1374 [==============================] - 1s 996us/step - loss: 0.6477 - accuracy: 0.6485\n",
      "1374/1374 [==============================] - 1s 1ms/step - loss: 0.6428 - accuracy: 0.6539\n",
      "1374/1374 [==============================] - 1s 1ms/step - loss: 0.6017 - accuracy: 0.6564\n",
      "1374/1374 [==============================] - 4s 3ms/step - loss: 0.6485 - accuracy: 0.6477\n",
      "1374/1374 [==============================] - 2s 1ms/step - loss: 0.6398 - accuracy: 0.6503\n",
      "1374/1374 [==============================] - 2s 1ms/step - loss: 0.6119 - accuracy: 0.6405\n",
      "2672/2672 [==============================] - 3s 1ms/step - loss: 0.6233 - accuracy: 0.6654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'batch_size': 20, 'nb_epoch': 500, 'optimizer': 'adam'}, 0.6671976538966404)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we need to fit our training set.\n",
    "\n",
    "grid_search = grid_search.fit(X_train,y_train)\n",
    "\n",
    "#we get the best selection of parameters using best_params from the grid search object\n",
    "\n",
    "best_param = grid_search.best_params_\n",
    "\n",
    "#we get the best accuracy score using best_score_\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "#NB: this process will take a while\n",
    "\n",
    "best_param, best_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
