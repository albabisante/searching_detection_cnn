{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_samples_from_csv(file_path, n_steps):\n",
    "    print(\"Downloading file\",file_path)\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    df_final = df.drop(['Unnamed: 0', 'lat', 'lon', 'date'],axis=1)\n",
    "\n",
    "    df_final = df_final.to_numpy()\n",
    "    \n",
    "    X, y = split_sequences(df_final, n_steps)\n",
    "    \n",
    "    print(\"Input shape (samples, number of steps, features): \",array(X).shape)\n",
    "    print(\"Target shape (samples): \",array(y).shape)\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file dataset/not_searching/csv/1222.json.csv\n",
      "Input shape (samples, number of steps, features):  (209, 5, 4)\n",
      "Target shape (samples):  (209,)\n",
      "Downloading file dataset/not_searching/csv/1254.json.csv\n",
      "Input shape (samples, number of steps, features):  (971, 5, 4)\n",
      "Target shape (samples):  (971,)\n",
      "Downloading file dataset/not_searching/csv/1423.json.csv\n",
      "Input shape (samples, number of steps, features):  (271, 5, 4)\n",
      "Target shape (samples):  (271,)\n",
      "Downloading file dataset/not_searching/csv/1538.json.csv\n",
      "Input shape (samples, number of steps, features):  (794, 5, 4)\n",
      "Target shape (samples):  (794,)\n",
      "Downloading file dataset/not_searching/csv/1546.json.csv\n",
      "Input shape (samples, number of steps, features):  (734, 5, 4)\n",
      "Target shape (samples):  (734,)\n",
      "Downloading file dataset/not_searching/csv/1550.json.csv\n",
      "Input shape (samples, number of steps, features):  (355, 5, 4)\n",
      "Target shape (samples):  (355,)\n",
      "Downloading file dataset/not_searching/csv/1552.json.csv\n",
      "Input shape (samples, number of steps, features):  (307, 5, 4)\n",
      "Target shape (samples):  (307,)\n",
      "Downloading file dataset/not_searching/csv/1638.json.csv\n",
      "Input shape (samples, number of steps, features):  (732, 5, 4)\n",
      "Target shape (samples):  (732,)\n",
      "Downloading file dataset/not_searching/csv/1645.json.csv\n",
      "Input shape (samples, number of steps, features):  (416, 5, 4)\n",
      "Target shape (samples):  (416,)\n",
      "Downloading file dataset/not_searching/csv/1649.json.csv\n",
      "Input shape (samples, number of steps, features):  (489, 5, 4)\n",
      "Target shape (samples):  (489,)\n",
      "Downloading file dataset/not_searching/csv/1673.json.csv\n",
      "Input shape (samples, number of steps, features):  (1640, 5, 4)\n",
      "Target shape (samples):  (1640,)\n",
      "Downloading file dataset/not_searching/csv/1677.json.csv\n",
      "Input shape (samples, number of steps, features):  (772, 5, 4)\n",
      "Target shape (samples):  (772,)\n",
      "Downloading file dataset/not_searching/csv/1683.json.csv\n",
      "Input shape (samples, number of steps, features):  (780, 5, 4)\n",
      "Target shape (samples):  (780,)\n",
      "Downloading file dataset/not_searching/csv/1711.json.csv\n",
      "Input shape (samples, number of steps, features):  (164, 5, 4)\n",
      "Target shape (samples):  (164,)\n",
      "Downloading file dataset/not_searching/csv/1755.json.csv\n",
      "Input shape (samples, number of steps, features):  (103, 5, 4)\n",
      "Target shape (samples):  (103,)\n",
      "Downloading file dataset/not_searching/csv/1759.json.csv\n",
      "Input shape (samples, number of steps, features):  (142, 5, 4)\n",
      "Target shape (samples):  (142,)\n",
      "Downloading file dataset/not_searching/csv/1761.json.csv\n",
      "Input shape (samples, number of steps, features):  (220, 5, 4)\n",
      "Target shape (samples):  (220,)\n",
      "Downloading file dataset/not_searching/csv/1767.json.csv\n",
      "Input shape (samples, number of steps, features):  (381, 5, 4)\n",
      "Target shape (samples):  (381,)\n",
      "Downloading file dataset/not_searching/csv/1769.json.csv\n",
      "Input shape (samples, number of steps, features):  (210, 5, 4)\n",
      "Target shape (samples):  (210,)\n",
      "Downloading file dataset/not_searching/csv/1774.json.csv\n",
      "Input shape (samples, number of steps, features):  (1248, 5, 4)\n",
      "Target shape (samples):  (1248,)\n",
      "Downloading file dataset/not_searching/csv/1802.json.csv\n",
      "Input shape (samples, number of steps, features):  (855, 5, 4)\n",
      "Target shape (samples):  (855,)\n",
      "Downloading file dataset/not_searching/csv/1804.json.csv\n",
      "Input shape (samples, number of steps, features):  (228, 5, 4)\n",
      "Target shape (samples):  (228,)\n",
      "Downloading file dataset/not_searching/csv/1817.json.csv\n",
      "Input shape (samples, number of steps, features):  (384, 5, 4)\n",
      "Target shape (samples):  (384,)\n",
      "Downloading file dataset/not_searching/csv/1843.json.csv\n",
      "Input shape (samples, number of steps, features):  (129, 5, 4)\n",
      "Target shape (samples):  (129,)\n",
      "Downloading file dataset/not_searching/csv/1860.json.csv\n",
      "Input shape (samples, number of steps, features):  (259, 5, 4)\n",
      "Target shape (samples):  (259,)\n",
      "Downloading file dataset/not_searching/csv/1864.json.csv\n",
      "Input shape (samples, number of steps, features):  (211, 5, 4)\n",
      "Target shape (samples):  (211,)\n",
      "Downloading file dataset/not_searching/csv/1866.json.csv\n",
      "Input shape (samples, number of steps, features):  (725, 5, 4)\n",
      "Target shape (samples):  (725,)\n",
      "Downloading file dataset/not_searching/csv/1868.json.csv\n",
      "Input shape (samples, number of steps, features):  (248, 5, 4)\n",
      "Target shape (samples):  (248,)\n",
      "Downloading file dataset/not_searching/csv/1870.json.csv\n",
      "Input shape (samples, number of steps, features):  (285, 5, 4)\n",
      "Target shape (samples):  (285,)\n",
      "Downloading file dataset/not_searching/csv/1874.json.csv\n",
      "Input shape (samples, number of steps, features):  (411, 5, 4)\n",
      "Target shape (samples):  (411,)\n",
      "Downloading file dataset/not_searching/csv/1876.json.csv\n",
      "Input shape (samples, number of steps, features):  (470, 5, 4)\n",
      "Target shape (samples):  (470,)\n",
      "Downloading file dataset/not_searching/csv/1878.json.csv\n",
      "Input shape (samples, number of steps, features):  (254, 5, 4)\n",
      "Target shape (samples):  (254,)\n",
      "Downloading file dataset/not_searching/csv/1880.json.csv\n",
      "Input shape (samples, number of steps, features):  (340, 5, 4)\n",
      "Target shape (samples):  (340,)\n",
      "Downloading file dataset/not_searching/csv/1891.json.csv\n",
      "Input shape (samples, number of steps, features):  (496, 5, 4)\n",
      "Target shape (samples):  (496,)\n",
      "Downloading file dataset/not_searching/csv/1948.json.csv\n",
      "Input shape (samples, number of steps, features):  (335, 5, 4)\n",
      "Target shape (samples):  (335,)\n",
      "Downloading file dataset/not_searching/csv/1959.json.csv\n",
      "Input shape (samples, number of steps, features):  (0,)\n",
      "Target shape (samples):  (0,)\n",
      "Downloading file dataset/not_searching/csv/2134.json.csv\n",
      "Input shape (samples, number of steps, features):  (1109, 5, 4)\n",
      "Target shape (samples):  (1109,)\n",
      "Downloading file dataset/not_searching/csv/2142.json.csv\n",
      "Input shape (samples, number of steps, features):  (818, 5, 4)\n",
      "Target shape (samples):  (818,)\n",
      "Downloading file dataset/not_searching/csv/2144.json.csv\n",
      "Input shape (samples, number of steps, features):  (277, 5, 4)\n",
      "Target shape (samples):  (277,)\n",
      "Downloading file dataset/not_searching/csv/2150.json.csv\n",
      "Input shape (samples, number of steps, features):  (484, 5, 4)\n",
      "Target shape (samples):  (484,)\n",
      "Downloading file dataset/not_searching/csv/2199.json.csv\n",
      "Input shape (samples, number of steps, features):  (529, 5, 4)\n",
      "Target shape (samples):  (529,)\n",
      "Downloading file dataset/not_searching/csv/2204.json.csv\n",
      "Input shape (samples, number of steps, features):  (181, 5, 4)\n",
      "Target shape (samples):  (181,)\n",
      "Downloading file dataset/not_searching/csv/2206.json.csv\n",
      "Input shape (samples, number of steps, features):  (843, 5, 4)\n",
      "Target shape (samples):  (843,)\n",
      "Downloading file dataset/not_searching/csv/2311.json.csv\n",
      "Input shape (samples, number of steps, features):  (383, 5, 4)\n",
      "Target shape (samples):  (383,)\n",
      "Downloading file dataset/not_searching/csv/2489.json.csv\n",
      "Input shape (samples, number of steps, features):  (421, 5, 4)\n",
      "Target shape (samples):  (421,)\n",
      "Downloading file dataset/not_searching/csv/2603.json.csv\n",
      "Input shape (samples, number of steps, features):  (0,)\n",
      "Target shape (samples):  (0,)\n",
      "Downloading file dataset/not_searching/csv/2675.json.csv\n",
      "Input shape (samples, number of steps, features):  (703, 5, 4)\n",
      "Target shape (samples):  (703,)\n",
      "Downloading file dataset/not_searching/csv/2715.json.csv\n",
      "Input shape (samples, number of steps, features):  (793, 5, 4)\n",
      "Target shape (samples):  (793,)\n",
      "Downloading file dataset/not_searching/csv/2718.json.csv\n",
      "Input shape (samples, number of steps, features):  (534, 5, 4)\n",
      "Target shape (samples):  (534,)\n",
      "Downloading file dataset/not_searching/csv/3196.json.csv\n",
      "Input shape (samples, number of steps, features):  (357, 5, 4)\n",
      "Target shape (samples):  (357,)\n",
      "Downloading file dataset/not_searching/csv/3207.json.csv\n",
      "Input shape (samples, number of steps, features):  (159, 5, 4)\n",
      "Target shape (samples):  (159,)\n",
      "Downloading file dataset/not_searching/csv/3347.json.csv\n",
      "Input shape (samples, number of steps, features):  (602, 5, 4)\n",
      "Target shape (samples):  (602,)\n",
      "Downloading file dataset/not_searching/csv/3491.json.csv\n",
      "Input shape (samples, number of steps, features):  (1185, 5, 4)\n",
      "Target shape (samples):  (1185,)\n",
      "Downloading file dataset/not_searching/csv/3513.json.csv\n",
      "Input shape (samples, number of steps, features):  (1150, 5, 4)\n",
      "Target shape (samples):  (1150,)\n",
      "Downloading file dataset/not_searching/csv/3633.json.csv\n",
      "Input shape (samples, number of steps, features):  (939, 5, 4)\n",
      "Target shape (samples):  (939,)\n",
      "Downloading file dataset/not_searching/csv/3671.json.csv\n",
      "Input shape (samples, number of steps, features):  (594, 5, 4)\n",
      "Target shape (samples):  (594,)\n",
      "Downloading file dataset/not_searching/csv/4002.json.csv\n",
      "Input shape (samples, number of steps, features):  (0,)\n",
      "Target shape (samples):  (0,)\n",
      "Downloading file dataset/not_searching/csv/4076.json.csv\n",
      "Input shape (samples, number of steps, features):  (654, 5, 4)\n",
      "Target shape (samples):  (654,)\n",
      "Downloading file dataset/not_searching/csv/4488.json.csv\n",
      "Input shape (samples, number of steps, features):  (784, 5, 4)\n",
      "Target shape (samples):  (784,)\n",
      "Downloading file dataset/not_searching/csv/4505.json.csv\n",
      "Input shape (samples, number of steps, features):  (1192, 5, 4)\n",
      "Target shape (samples):  (1192,)\n",
      "Downloading file dataset/not_searching/csv/4849.json.csv\n",
      "Input shape (samples, number of steps, features):  (925, 5, 4)\n",
      "Target shape (samples):  (925,)\n",
      "Downloading file dataset/not_searching/csv/5397.json.csv\n",
      "Input shape (samples, number of steps, features):  (887, 5, 4)\n",
      "Target shape (samples):  (887,)\n",
      "Downloading file dataset/not_searching/csv/5417.json.csv\n",
      "Input shape (samples, number of steps, features):  (916, 5, 4)\n",
      "Target shape (samples):  (916,)\n",
      "Downloading file dataset/not_searching/csv/5419.json.csv\n",
      "Input shape (samples, number of steps, features):  (436, 5, 4)\n",
      "Target shape (samples):  (436,)\n",
      "Downloading file dataset/not_searching/csv/5421.json.csv\n",
      "Input shape (samples, number of steps, features):  (387, 5, 4)\n",
      "Target shape (samples):  (387,)\n",
      "Downloading file dataset/not_searching/csv/5443.json.csv\n",
      "Input shape (samples, number of steps, features):  (231, 5, 4)\n",
      "Target shape (samples):  (231,)\n",
      "Downloading file dataset/not_searching/csv/5470.json.csv\n",
      "Input shape (samples, number of steps, features):  (804, 5, 4)\n",
      "Target shape (samples):  (804,)\n",
      "Downloading file dataset/not_searching/csv/5474.json.csv\n",
      "Input shape (samples, number of steps, features):  (298, 5, 4)\n",
      "Target shape (samples):  (298,)\n",
      "Downloading file dataset/not_searching/csv/5516.json.csv\n",
      "Input shape (samples, number of steps, features):  (649, 5, 4)\n",
      "Target shape (samples):  (649,)\n",
      "Downloading file dataset/not_searching/csv/5518.json.csv\n",
      "Input shape (samples, number of steps, features):  (404, 5, 4)\n",
      "Target shape (samples):  (404,)\n",
      "Downloading file dataset/not_searching/csv/5525.json.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (samples, number of steps, features):  (560, 5, 4)\n",
      "Target shape (samples):  (560,)\n",
      "Downloading file dataset/not_searching/csv/5529.json.csv\n",
      "Input shape (samples, number of steps, features):  (733, 5, 4)\n",
      "Target shape (samples):  (733,)\n",
      "Downloading file dataset/not_searching/csv/5607.json.csv\n",
      "Input shape (samples, number of steps, features):  (540, 5, 4)\n",
      "Target shape (samples):  (540,)\n",
      "Downloading file dataset/not_searching/csv/5617.json.csv\n",
      "Input shape (samples, number of steps, features):  (998, 5, 4)\n",
      "Target shape (samples):  (998,)\n",
      "Downloading file dataset/not_searching/csv/5649.json.csv\n",
      "Input shape (samples, number of steps, features):  (669, 5, 4)\n",
      "Target shape (samples):  (669,)\n",
      "Downloading file dataset/not_searching/csv/5656.json.csv\n",
      "Input shape (samples, number of steps, features):  (1079, 5, 4)\n",
      "Target shape (samples):  (1079,)\n",
      "Downloading file dataset/not_searching/csv/5658.json.csv\n",
      "Input shape (samples, number of steps, features):  (1984, 5, 4)\n",
      "Target shape (samples):  (1984,)\n",
      "Downloading file dataset/not_searching/csv/5666.json.csv\n",
      "Input shape (samples, number of steps, features):  (667, 5, 4)\n",
      "Target shape (samples):  (667,)\n",
      "Downloading file dataset/not_searching/csv/5779.json.csv\n",
      "Input shape (samples, number of steps, features):  (659, 5, 4)\n",
      "Target shape (samples):  (659,)\n",
      "Downloading file dataset/not_searching/csv/5920.json.csv\n",
      "Input shape (samples, number of steps, features):  (568, 5, 4)\n",
      "Target shape (samples):  (568,)\n",
      "Downloading file dataset/not_searching/csv/5939.json.csv\n",
      "Input shape (samples, number of steps, features):  (42, 5, 4)\n",
      "Target shape (samples):  (42,)\n",
      "Downloading file dataset/not_searching/csv/5945.json.csv\n",
      "Input shape (samples, number of steps, features):  (1070, 5, 4)\n",
      "Target shape (samples):  (1070,)\n",
      "Downloading file dataset/not_searching/csv/5951.json.csv\n",
      "Input shape (samples, number of steps, features):  (661, 5, 4)\n",
      "Target shape (samples):  (661,)\n",
      "Downloading file dataset/not_searching/csv/5957.json.csv\n",
      "Input shape (samples, number of steps, features):  (996, 5, 4)\n",
      "Target shape (samples):  (996,)\n",
      "Downloading file dataset/not_searching/csv/5980.json.csv\n",
      "Input shape (samples, number of steps, features):  (530, 5, 4)\n",
      "Target shape (samples):  (530,)\n",
      "Downloading file dataset/not_searching/csv/6013.json.csv\n",
      "Input shape (samples, number of steps, features):  (836, 5, 4)\n",
      "Target shape (samples):  (836,)\n",
      "Downloading file dataset/not_searching/csv/6022.json.csv\n",
      "Input shape (samples, number of steps, features):  (1641, 5, 4)\n",
      "Target shape (samples):  (1641,)\n",
      "Downloading file dataset/not_searching/csv/6024.json.csv\n",
      "Input shape (samples, number of steps, features):  (673, 5, 4)\n",
      "Target shape (samples):  (673,)\n",
      "Downloading file dataset/not_searching/csv/6028.json.csv\n",
      "Input shape (samples, number of steps, features):  (847, 5, 4)\n",
      "Target shape (samples):  (847,)\n",
      "Downloading file dataset/searching/csv/1222.json.csv\n",
      "Input shape (samples, number of steps, features):  (187, 5, 4)\n",
      "Target shape (samples):  (187,)\n",
      "Downloading file dataset/searching/csv/1254.json.csv\n",
      "Input shape (samples, number of steps, features):  (465, 5, 4)\n",
      "Target shape (samples):  (465,)\n",
      "Downloading file dataset/searching/csv/1423.json.csv\n",
      "Input shape (samples, number of steps, features):  (273, 5, 4)\n",
      "Target shape (samples):  (273,)\n",
      "Downloading file dataset/searching/csv/1538.json.csv\n",
      "Input shape (samples, number of steps, features):  (96, 5, 4)\n",
      "Target shape (samples):  (96,)\n",
      "Downloading file dataset/searching/csv/1546.json.csv\n",
      "Input shape (samples, number of steps, features):  (255, 5, 4)\n",
      "Target shape (samples):  (255,)\n",
      "Downloading file dataset/searching/csv/1550.json.csv\n",
      "Input shape (samples, number of steps, features):  (224, 5, 4)\n",
      "Target shape (samples):  (224,)\n",
      "Downloading file dataset/searching/csv/1552.json.csv\n",
      "Input shape (samples, number of steps, features):  (431, 5, 4)\n",
      "Target shape (samples):  (431,)\n",
      "Downloading file dataset/searching/csv/1638.json.csv\n",
      "Input shape (samples, number of steps, features):  (312, 5, 4)\n",
      "Target shape (samples):  (312,)\n",
      "Downloading file dataset/searching/csv/1645.json.csv\n",
      "Input shape (samples, number of steps, features):  (249, 5, 4)\n",
      "Target shape (samples):  (249,)\n",
      "Downloading file dataset/searching/csv/1649.json.csv\n",
      "Input shape (samples, number of steps, features):  (369, 5, 4)\n",
      "Target shape (samples):  (369,)\n",
      "Downloading file dataset/searching/csv/1673.json.csv\n",
      "Input shape (samples, number of steps, features):  (301, 5, 4)\n",
      "Target shape (samples):  (301,)\n",
      "Downloading file dataset/searching/csv/1677.json.csv\n",
      "Input shape (samples, number of steps, features):  (205, 5, 4)\n",
      "Target shape (samples):  (205,)\n",
      "Downloading file dataset/searching/csv/1683.json.csv\n",
      "Input shape (samples, number of steps, features):  (392, 5, 4)\n",
      "Target shape (samples):  (392,)\n",
      "Downloading file dataset/searching/csv/1711.json.csv\n",
      "Input shape (samples, number of steps, features):  (136, 5, 4)\n",
      "Target shape (samples):  (136,)\n",
      "Downloading file dataset/searching/csv/1755.json.csv\n",
      "Input shape (samples, number of steps, features):  (143, 5, 4)\n",
      "Target shape (samples):  (143,)\n",
      "Downloading file dataset/searching/csv/1759.json.csv\n",
      "Input shape (samples, number of steps, features):  (199, 5, 4)\n",
      "Target shape (samples):  (199,)\n",
      "Downloading file dataset/searching/csv/1761.json.csv\n",
      "Input shape (samples, number of steps, features):  (266, 5, 4)\n",
      "Target shape (samples):  (266,)\n",
      "Downloading file dataset/searching/csv/1767.json.csv\n",
      "Input shape (samples, number of steps, features):  (221, 5, 4)\n",
      "Target shape (samples):  (221,)\n",
      "Downloading file dataset/searching/csv/1769.json.csv\n",
      "Input shape (samples, number of steps, features):  (441, 5, 4)\n",
      "Target shape (samples):  (441,)\n",
      "Downloading file dataset/searching/csv/1774.json.csv\n",
      "Input shape (samples, number of steps, features):  (218, 5, 4)\n",
      "Target shape (samples):  (218,)\n",
      "Downloading file dataset/searching/csv/1802.json.csv\n",
      "Input shape (samples, number of steps, features):  (303, 5, 4)\n",
      "Target shape (samples):  (303,)\n",
      "Downloading file dataset/searching/csv/1804.json.csv\n",
      "Input shape (samples, number of steps, features):  (266, 5, 4)\n",
      "Target shape (samples):  (266,)\n",
      "Downloading file dataset/searching/csv/1817.json.csv\n",
      "Input shape (samples, number of steps, features):  (178, 5, 4)\n",
      "Target shape (samples):  (178,)\n",
      "Downloading file dataset/searching/csv/1843.json.csv\n",
      "Input shape (samples, number of steps, features):  (172, 5, 4)\n",
      "Target shape (samples):  (172,)\n",
      "Downloading file dataset/searching/csv/1860.json.csv\n",
      "Input shape (samples, number of steps, features):  (375, 5, 4)\n",
      "Target shape (samples):  (375,)\n",
      "Downloading file dataset/searching/csv/1864.json.csv\n",
      "Input shape (samples, number of steps, features):  (310, 5, 4)\n",
      "Target shape (samples):  (310,)\n",
      "Downloading file dataset/searching/csv/1866.json.csv\n",
      "Input shape (samples, number of steps, features):  (88, 5, 4)\n",
      "Target shape (samples):  (88,)\n",
      "Downloading file dataset/searching/csv/1868.json.csv\n",
      "Input shape (samples, number of steps, features):  (477, 5, 4)\n",
      "Target shape (samples):  (477,)\n",
      "Downloading file dataset/searching/csv/1870.json.csv\n",
      "Input shape (samples, number of steps, features):  (157, 5, 4)\n",
      "Target shape (samples):  (157,)\n",
      "Downloading file dataset/searching/csv/1874.json.csv\n",
      "Input shape (samples, number of steps, features):  (994, 5, 4)\n",
      "Target shape (samples):  (994,)\n",
      "Downloading file dataset/searching/csv/1876.json.csv\n",
      "Input shape (samples, number of steps, features):  (197, 5, 4)\n",
      "Target shape (samples):  (197,)\n",
      "Downloading file dataset/searching/csv/1878.json.csv\n",
      "Input shape (samples, number of steps, features):  (260, 5, 4)\n",
      "Target shape (samples):  (260,)\n",
      "Downloading file dataset/searching/csv/1880.json.csv\n",
      "Input shape (samples, number of steps, features):  (292, 5, 4)\n",
      "Target shape (samples):  (292,)\n",
      "Downloading file dataset/searching/csv/1891.json.csv\n",
      "Input shape (samples, number of steps, features):  (65, 5, 4)\n",
      "Target shape (samples):  (65,)\n",
      "Downloading file dataset/searching/csv/1948.json.csv\n",
      "Input shape (samples, number of steps, features):  (353, 5, 4)\n",
      "Target shape (samples):  (353,)\n",
      "Downloading file dataset/searching/csv/1959.json.csv\n",
      "Input shape (samples, number of steps, features):  (833, 5, 4)\n",
      "Target shape (samples):  (833,)\n",
      "Downloading file dataset/searching/csv/2134.json.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (samples, number of steps, features):  (269, 5, 4)\n",
      "Target shape (samples):  (269,)\n",
      "Downloading file dataset/searching/csv/2142.json.csv\n",
      "Input shape (samples, number of steps, features):  (251, 5, 4)\n",
      "Target shape (samples):  (251,)\n",
      "Downloading file dataset/searching/csv/2144.json.csv\n",
      "Input shape (samples, number of steps, features):  (475, 5, 4)\n",
      "Target shape (samples):  (475,)\n",
      "Downloading file dataset/searching/csv/2150.json.csv\n",
      "Input shape (samples, number of steps, features):  (256, 5, 4)\n",
      "Target shape (samples):  (256,)\n",
      "Downloading file dataset/searching/csv/2199.json.csv\n",
      "Input shape (samples, number of steps, features):  (776, 5, 4)\n",
      "Target shape (samples):  (776,)\n",
      "Downloading file dataset/searching/csv/2204.json.csv\n",
      "Input shape (samples, number of steps, features):  (179, 5, 4)\n",
      "Target shape (samples):  (179,)\n",
      "Downloading file dataset/searching/csv/2206.json.csv\n",
      "Input shape (samples, number of steps, features):  (227, 5, 4)\n",
      "Target shape (samples):  (227,)\n",
      "Downloading file dataset/searching/csv/2311.json.csv\n",
      "Input shape (samples, number of steps, features):  (384, 5, 4)\n",
      "Target shape (samples):  (384,)\n",
      "Downloading file dataset/searching/csv/2489.json.csv\n",
      "Input shape (samples, number of steps, features):  (145, 5, 4)\n",
      "Target shape (samples):  (145,)\n",
      "Downloading file dataset/searching/csv/2603.json.csv\n",
      "Input shape (samples, number of steps, features):  (383, 5, 4)\n",
      "Target shape (samples):  (383,)\n",
      "Downloading file dataset/searching/csv/2675.json.csv\n",
      "Input shape (samples, number of steps, features):  (261, 5, 4)\n",
      "Target shape (samples):  (261,)\n",
      "Downloading file dataset/searching/csv/2715.json.csv\n",
      "Input shape (samples, number of steps, features):  (164, 5, 4)\n",
      "Target shape (samples):  (164,)\n",
      "Downloading file dataset/searching/csv/2718.json.csv\n",
      "Input shape (samples, number of steps, features):  (333, 5, 4)\n",
      "Target shape (samples):  (333,)\n",
      "Downloading file dataset/searching/csv/3196.json.csv\n",
      "Input shape (samples, number of steps, features):  (34, 5, 4)\n",
      "Target shape (samples):  (34,)\n",
      "Downloading file dataset/searching/csv/3207.json.csv\n",
      "Input shape (samples, number of steps, features):  (241, 5, 4)\n",
      "Target shape (samples):  (241,)\n",
      "Downloading file dataset/searching/csv/3347.json.csv\n",
      "Input shape (samples, number of steps, features):  (146, 5, 4)\n",
      "Target shape (samples):  (146,)\n",
      "Downloading file dataset/searching/csv/3491.json.csv\n",
      "Input shape (samples, number of steps, features):  (332, 5, 4)\n",
      "Target shape (samples):  (332,)\n",
      "Downloading file dataset/searching/csv/3513.json.csv\n",
      "Input shape (samples, number of steps, features):  (134, 5, 4)\n",
      "Target shape (samples):  (134,)\n",
      "Downloading file dataset/searching/csv/3633.json.csv\n",
      "Input shape (samples, number of steps, features):  (294, 5, 4)\n",
      "Target shape (samples):  (294,)\n",
      "Downloading file dataset/searching/csv/3671.json.csv\n",
      "Input shape (samples, number of steps, features):  (220, 5, 4)\n",
      "Target shape (samples):  (220,)\n",
      "Downloading file dataset/searching/csv/4002.json.csv\n",
      "Input shape (samples, number of steps, features):  (321, 5, 4)\n",
      "Target shape (samples):  (321,)\n",
      "Downloading file dataset/searching/csv/4076.json.csv\n",
      "Input shape (samples, number of steps, features):  (705, 5, 4)\n",
      "Target shape (samples):  (705,)\n",
      "Downloading file dataset/searching/csv/4488.json.csv\n",
      "Input shape (samples, number of steps, features):  (305, 5, 4)\n",
      "Target shape (samples):  (305,)\n",
      "Downloading file dataset/searching/csv/4505.json.csv\n",
      "Input shape (samples, number of steps, features):  (482, 5, 4)\n",
      "Target shape (samples):  (482,)\n",
      "Downloading file dataset/searching/csv/4849.json.csv\n",
      "Input shape (samples, number of steps, features):  (217, 5, 4)\n",
      "Target shape (samples):  (217,)\n",
      "Downloading file dataset/searching/csv/5397.json.csv\n",
      "Input shape (samples, number of steps, features):  (1021, 5, 4)\n",
      "Target shape (samples):  (1021,)\n",
      "Downloading file dataset/searching/csv/5417.json.csv\n",
      "Input shape (samples, number of steps, features):  (237, 5, 4)\n",
      "Target shape (samples):  (237,)\n",
      "Downloading file dataset/searching/csv/5419.json.csv\n",
      "Input shape (samples, number of steps, features):  (359, 5, 4)\n",
      "Target shape (samples):  (359,)\n",
      "Downloading file dataset/searching/csv/5421.json.csv\n",
      "Input shape (samples, number of steps, features):  (425, 5, 4)\n",
      "Target shape (samples):  (425,)\n",
      "Downloading file dataset/searching/csv/5443.json.csv\n",
      "Input shape (samples, number of steps, features):  (348, 5, 4)\n",
      "Target shape (samples):  (348,)\n",
      "Downloading file dataset/searching/csv/5470.json.csv\n",
      "Input shape (samples, number of steps, features):  (52, 5, 4)\n",
      "Target shape (samples):  (52,)\n",
      "Downloading file dataset/searching/csv/5474.json.csv\n",
      "Input shape (samples, number of steps, features):  (372, 5, 4)\n",
      "Target shape (samples):  (372,)\n",
      "Downloading file dataset/searching/csv/5516.json.csv\n",
      "Input shape (samples, number of steps, features):  (515, 5, 4)\n",
      "Target shape (samples):  (515,)\n",
      "Downloading file dataset/searching/csv/5518.json.csv\n",
      "Input shape (samples, number of steps, features):  (185, 5, 4)\n",
      "Target shape (samples):  (185,)\n",
      "Downloading file dataset/searching/csv/5525.json.csv\n",
      "Input shape (samples, number of steps, features):  (190, 5, 4)\n",
      "Target shape (samples):  (190,)\n",
      "Downloading file dataset/searching/csv/5529.json.csv\n",
      "Input shape (samples, number of steps, features):  (49, 5, 4)\n",
      "Target shape (samples):  (49,)\n",
      "Downloading file dataset/searching/csv/5607.json.csv\n",
      "Input shape (samples, number of steps, features):  (379, 5, 4)\n",
      "Target shape (samples):  (379,)\n",
      "Downloading file dataset/searching/csv/5617.json.csv\n",
      "Input shape (samples, number of steps, features):  (289, 5, 4)\n",
      "Target shape (samples):  (289,)\n",
      "Downloading file dataset/searching/csv/5649.json.csv\n",
      "Input shape (samples, number of steps, features):  (755, 5, 4)\n",
      "Target shape (samples):  (755,)\n",
      "Downloading file dataset/searching/csv/5656.json.csv\n",
      "Input shape (samples, number of steps, features):  (174, 5, 4)\n",
      "Target shape (samples):  (174,)\n",
      "Downloading file dataset/searching/csv/5658.json.csv\n",
      "Input shape (samples, number of steps, features):  (369, 5, 4)\n",
      "Target shape (samples):  (369,)\n",
      "Downloading file dataset/searching/csv/5666.json.csv\n",
      "Input shape (samples, number of steps, features):  (50, 5, 4)\n",
      "Target shape (samples):  (50,)\n",
      "Downloading file dataset/searching/csv/5779.json.csv\n",
      "Input shape (samples, number of steps, features):  (392, 5, 4)\n",
      "Target shape (samples):  (392,)\n",
      "Downloading file dataset/searching/csv/5920.json.csv\n",
      "Input shape (samples, number of steps, features):  (337, 5, 4)\n",
      "Target shape (samples):  (337,)\n",
      "Downloading file dataset/searching/csv/5939.json.csv\n",
      "Input shape (samples, number of steps, features):  (215, 5, 4)\n",
      "Target shape (samples):  (215,)\n",
      "Downloading file dataset/searching/csv/5945.json.csv\n",
      "Input shape (samples, number of steps, features):  (1406, 5, 4)\n",
      "Target shape (samples):  (1406,)\n",
      "Downloading file dataset/searching/csv/5951.json.csv\n",
      "Input shape (samples, number of steps, features):  (559, 5, 4)\n",
      "Target shape (samples):  (559,)\n",
      "Downloading file dataset/searching/csv/5957.json.csv\n",
      "Input shape (samples, number of steps, features):  (304, 5, 4)\n",
      "Target shape (samples):  (304,)\n",
      "Downloading file dataset/searching/csv/5980.json.csv\n",
      "Input shape (samples, number of steps, features):  (203, 5, 4)\n",
      "Target shape (samples):  (203,)\n",
      "Downloading file dataset/searching/csv/6013.json.csv\n",
      "Input shape (samples, number of steps, features):  (374, 5, 4)\n",
      "Target shape (samples):  (374,)\n",
      "Downloading file dataset/searching/csv/6022.json.csv\n",
      "Input shape (samples, number of steps, features):  (237, 5, 4)\n",
      "Target shape (samples):  (237,)\n",
      "Downloading file dataset/searching/csv/6024.json.csv\n",
      "Input shape (samples, number of steps, features):  (415, 5, 4)\n",
      "Target shape (samples):  (415,)\n",
      "Downloading file dataset/searching/csv/6028.json.csv\n",
      "Input shape (samples, number of steps, features):  (226, 5, 4)\n",
      "Target shape (samples):  (226,)\n",
      "Final dataset:  (81623, 5, 4) (81623,)\n"
     ]
    }
   ],
   "source": [
    "#Choose time interval\n",
    "n_steps = 5\n",
    "\n",
    "samples_X = []\n",
    "samples_y = []\n",
    "\n",
    "#retrieve samples from trip csv\n",
    "not_searching_trips = sorted(os.listdir(\"dataset/not_searching/csv\"))\n",
    "for trip in not_searching_trips:\n",
    "    if trip != \".DS_Store\":\n",
    "        X, y = retrieve_samples_from_csv(\"dataset/not_searching/csv/\"+trip, n_steps)\n",
    "        samples_X += X\n",
    "        samples_y += y\n",
    "\n",
    "searching_trips = sorted(os.listdir(\"dataset/searching/csv\"))\n",
    "for trip in searching_trips:\n",
    "    if trip != \".DS_Store\":\n",
    "        X, y = retrieve_samples_from_csv(\"dataset/searching/csv/\"+trip, n_steps)\n",
    "        samples_X += X\n",
    "        samples_y += y\n",
    "    \n",
    "#transform them in numpy arrays\n",
    "X = array(samples_X)\n",
    "y = array(samples_y)\n",
    "\n",
    "# dataset number of features\n",
    "n_features = X.shape[2]\n",
    "\n",
    "print(\"Final dataset: \", X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73460, 5, 4) (8163, 5, 4)\n"
     ]
    }
   ],
   "source": [
    "#We split the data into a training and test set. We use 0.9 of the data for training and 0.1 for testing.\n",
    "\n",
    "#X_train represents the independent variables we’re using to train\n",
    "#y_train represents the column we’re predicting\n",
    "\n",
    "#X_test represents the independent variables we’re using to test\n",
    "#y_test represents the column we’re predicting during tests\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "#Feature scaling standardizes the range of our independent variables.\n",
    "X_train =  TimeSeriesScalerMeanVariance(mu=0.,std=1.).fit_transform(X_train)\n",
    "X_test = TimeSeriesScalerMeanVariance(mu=0.,std=1.).fit_transform(X_test)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "#model.add(Dense(1))\n",
    "model.compile(optimizer= 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "#model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1470/1470 [==============================] - 4s 3ms/step - loss: 0.6394 - accuracy: 0.6479 - val_loss: 0.6303 - val_accuracy: 0.6477\n",
      "Epoch 2/30\n",
      "1470/1470 [==============================] - 4s 3ms/step - loss: 0.6246 - accuracy: 0.6464 - val_loss: 0.6194 - val_accuracy: 0.6494\n",
      "Epoch 3/30\n",
      "1470/1470 [==============================] - 4s 3ms/step - loss: 0.6192 - accuracy: 0.6463 - val_loss: 0.6168 - val_accuracy: 0.6496\n",
      "Epoch 4/30\n",
      "1470/1470 [==============================] - 4s 3ms/step - loss: 0.6156 - accuracy: 0.6480 - val_loss: 0.6135 - val_accuracy: 0.6503\n",
      "Epoch 5/30\n",
      "1470/1470 [==============================] - 5s 3ms/step - loss: 0.6144 - accuracy: 0.6479 - val_loss: 0.6133 - val_accuracy: 0.6506\n",
      "Epoch 6/30\n",
      "1470/1470 [==============================] - 4s 3ms/step - loss: 0.6128 - accuracy: 0.6484 - val_loss: 0.6144 - val_accuracy: 0.6487\n",
      "Epoch 7/30\n",
      "1470/1470 [==============================] - 4s 3ms/step - loss: 0.6118 - accuracy: 0.6488 - val_loss: 0.6115 - val_accuracy: 0.6487\n",
      "Epoch 8/30\n",
      "1470/1470 [==============================] - 4s 3ms/step - loss: 0.6110 - accuracy: 0.6504 - val_loss: 0.6113 - val_accuracy: 0.6484\n",
      "Epoch 9/30\n",
      "1470/1470 [==============================] - 4s 3ms/step - loss: 0.6100 - accuracy: 0.6500 - val_loss: 0.6133 - val_accuracy: 0.6513\n",
      "Epoch 10/30\n",
      "1470/1470 [==============================] - 5s 3ms/step - loss: 0.6094 - accuracy: 0.6513 - val_loss: 0.6122 - val_accuracy: 0.6492\n",
      "Epoch 11/30\n",
      "1470/1470 [==============================] - 5s 3ms/step - loss: 0.6087 - accuracy: 0.6512 - val_loss: 0.6105 - val_accuracy: 0.6503\n",
      "Epoch 12/30\n",
      "1470/1470 [==============================] - 5s 3ms/step - loss: 0.6084 - accuracy: 0.6513 - val_loss: 0.6098 - val_accuracy: 0.6510\n",
      "Epoch 13/30\n",
      "1470/1470 [==============================] - 5s 4ms/step - loss: 0.6075 - accuracy: 0.6524 - val_loss: 0.6104 - val_accuracy: 0.6482\n",
      "Epoch 14/30\n",
      "1470/1470 [==============================] - 5s 4ms/step - loss: 0.6068 - accuracy: 0.6534 - val_loss: 0.6117 - val_accuracy: 0.6479\n",
      "Epoch 15/30\n",
      "1470/1470 [==============================] - 5s 3ms/step - loss: 0.6063 - accuracy: 0.6539 - val_loss: 0.6110 - val_accuracy: 0.6506\n",
      "Epoch 16/30\n",
      "1470/1470 [==============================] - 4s 3ms/step - loss: 0.6063 - accuracy: 0.6543 - val_loss: 0.6113 - val_accuracy: 0.6523\n",
      "Epoch 17/30\n",
      "1470/1470 [==============================] - 4s 3ms/step - loss: 0.6059 - accuracy: 0.6546 - val_loss: 0.6093 - val_accuracy: 0.6525\n",
      "Epoch 18/30\n",
      "1470/1470 [==============================] - 4s 3ms/step - loss: 0.6047 - accuracy: 0.6551 - val_loss: 0.6147 - val_accuracy: 0.6501\n",
      "Epoch 19/30\n",
      "1470/1470 [==============================] - 6s 4ms/step - loss: 0.6041 - accuracy: 0.6551 - val_loss: 0.6096 - val_accuracy: 0.6519\n",
      "Epoch 20/30\n",
      "1470/1470 [==============================] - 11s 8ms/step - loss: 0.6040 - accuracy: 0.6561 - val_loss: 0.6088 - val_accuracy: 0.6525\n",
      "Epoch 21/30\n",
      "1470/1470 [==============================] - 10s 7ms/step - loss: 0.6028 - accuracy: 0.6568 - val_loss: 0.6077 - val_accuracy: 0.6508\n",
      "Epoch 22/30\n",
      "1470/1470 [==============================] - 10s 7ms/step - loss: 0.6026 - accuracy: 0.6586 - val_loss: 0.6100 - val_accuracy: 0.6525\n",
      "Epoch 23/30\n",
      "1470/1470 [==============================] - 6s 4ms/step - loss: 0.6025 - accuracy: 0.6582 - val_loss: 0.6072 - val_accuracy: 0.6523\n",
      "Epoch 24/30\n",
      "1470/1470 [==============================] - 8s 5ms/step - loss: 0.6020 - accuracy: 0.6562 - val_loss: 0.6110 - val_accuracy: 0.65041s - loss: 0.6028  - ETA: 1s\n",
      "Epoch 25/30\n",
      "1470/1470 [==============================] - 10s 7ms/step - loss: 0.6017 - accuracy: 0.6574 - val_loss: 0.6071 - val_accuracy: 0.6521\n",
      "Epoch 26/30\n",
      "1470/1470 [==============================] - 5s 3ms/step - loss: 0.6018 - accuracy: 0.6581 - val_loss: 0.6080 - val_accuracy: 0.6555\n",
      "Epoch 27/30\n",
      "1470/1470 [==============================] - 4s 3ms/step - loss: 0.6004 - accuracy: 0.6576 - val_loss: 0.6110 - val_accuracy: 0.6504\n",
      "Epoch 28/30\n",
      "1470/1470 [==============================] - 5s 3ms/step - loss: 0.6007 - accuracy: 0.6591 - val_loss: 0.6101 - val_accuracy: 0.6527\n",
      "Epoch 29/30\n",
      "1470/1470 [==============================] - 4s 3ms/step - loss: 0.5999 - accuracy: 0.6589 - val_loss: 0.6080 - val_accuracy: 0.6517\n",
      "Epoch 30/30\n",
      "1470/1470 [==============================] - 4s 3ms/step - loss: 0.5997 - accuracy: 0.6613 - val_loss: 0.6077 - val_accuracy: 0.6531\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "BATCH_SIZE = 35\n",
    "EPOCHS = 30\n",
    "\n",
    "\n",
    "# fit model\n",
    "history = model.fit(X_train, y_train, validation_split=0.3, batch_size=BATCH_SIZE,\n",
    "                      epochs=EPOCHS, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.65020945  0.          0.33129458 -1.50384005]\n",
      " [-0.4826086   0.          0.4417261  -0.71759794]\n",
      " [ 0.11787195  0.          0.55215763  0.11941069]\n",
      " [ 1.00747305  0.          0.66258916  1.05101365]\n",
      " [ 1.00747305  0.         -1.98776747  1.05101365]]\n",
      "[[0.2941603]]\n"
     ]
    }
   ],
   "source": [
    "#Prediction example - searching = 1\n",
    "\n",
    "x_input = array([[5.78000020980835,0,21,0.0032495404551960002], [6.829999923706055,0,22,0.0032555182901280004], \n",
    "                 [7.369999885559082,0,23,0.0032618821052950004], [8.170000076293945,0,24,0.0032689651254700003],\n",
    "                 [8.170000076293945,0,0,0.0032689651254700003]\n",
    "                ])\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_input = sc.fit_transform(x_input)\n",
    "print(x_input)\n",
    "\n",
    "x_input = x_input.reshape(1, n_steps, n_features)\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False]\n",
      " [False]\n",
      " [False]\n",
      " ...\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n"
     ]
    }
   ],
   "source": [
    "#Predicting using the training set\n",
    "\n",
    "#This will show us the probability of a searching status.\n",
    "#We then set a threshold of 50% for classifying a status as 'searching'.\n",
    "#Any status with a probability of 0.5 or more will be classified as 'searching'.\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5029,  271],\n",
       "       [2526,  337]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy and loss\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['accuracy'], \"g--\", label=\"Accuracy of training data\")\n",
    "plt.plot(history.history['val_accuracy'], \"g\", label=\"Accuracy of validation data\")\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Training Epoch')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0,1])\n",
    "plt.ylim(0)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# summarize history for accuracy and loss\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], \"r--\", label=\"Loss of training data\")\n",
    "plt.plot(history.history['val_loss'], \"r\", label=\"Loss of validation data\")\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.ylim(0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classifier(optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps, n_features)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    #model.add(Dense(1))\n",
    "    model.compile(optimizer= optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracies = cross_val_score(estimator = classifier,\n",
    "#                             X = X_train,\n",
    "#                             y = y_train,\n",
    "#                             cv = 10,\n",
    "#                             n_jobs = -1)\n",
    "\n",
    "#accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To obtain the relative accuracies we get the mean of the accuracies.\n",
    "\n",
    "#mean = accuracies.mean()\n",
    "\n",
    "#Then the variance.\n",
    "\n",
    "#variance = accuracies.var()\n",
    "\n",
    "#Goal: to have a small variance between the accuracies.\n",
    "\n",
    "#mean, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We’ll still use the KerasClassifier, \n",
    "#but we won’t pass the batch size and number of epochs \n",
    "#since these are the parameters we want to tune.\n",
    "\n",
    "classifier = KerasClassifier(build_fn = make_classifier)\n",
    "\n",
    "#Create a dictionary with the parameters we’d like to tune \n",
    "\n",
    "params = {\n",
    "    'batch_size':[20,32,35],\n",
    "    'nb_epoch':[30, 50,100,150],\n",
    "    'optimizer':['adam','rmsprop']\n",
    "}\n",
    "\n",
    "#We then use Grid Search to test these parameters.\n",
    "#It expects our estimator, the parameters we just defined, the scoring metric and the number of k-folds.\n",
    "\n",
    "grid_search = GridSearchCV(estimator=classifier,\n",
    "                           param_grid=params,\n",
    "                           scoring='accuracy',\n",
    "                           cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3306/3306 [==============================] - 6s 2ms/step - loss: 0.6337 - accuracy: 0.6484\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "3306/3306 [==============================] - 13s 4ms/step - loss: 0.6368 - accuracy: 0.6482\n",
      "3306/3306 [==============================] - 14s 4ms/step - loss: 0.6359 - accuracy: 0.6479\n",
      "3306/3306 [==============================] - 10s 3ms/step - loss: 0.6362 - accuracy: 0.6480 0s - loss: 0.6375 \n",
      "3306/3306 [==============================] - 9s 3ms/step - loss: 0.6386 - accuracy: 0.6477\n",
      "3306/3306 [==============================] - 9s 3ms/step - loss: 0.6372 - accuracy: 0.6466\n",
      "3306/3306 [==============================] - 6s 2ms/step - loss: 0.6379 - accuracy: 0.6470\n",
      "3306/3306 [==============================] - 7s 2ms/step - loss: 0.6377 - accuracy: 0.6465\n",
      "3306/3306 [==============================] - 6s 2ms/step - loss: 0.6368 - accuracy: 0.6464\n",
      "3306/3306 [==============================] - 7s 2ms/step - loss: 0.6380 - accuracy: 0.6470\n",
      "3306/3306 [==============================] - 5s 2ms/step - loss: 0.6385 - accuracy: 0.6467\n",
      "3306/3306 [==============================] - 6s 2ms/step - loss: 0.6387 - accuracy: 0.6469\n",
      "3306/3306 [==============================] - 7s 2ms/step - loss: 0.6371 - accuracy: 0.6465\n",
      "3306/3306 [==============================] - 9s 3ms/step - loss: 0.6377 - accuracy: 0.6474: 0s - loss: 0.6379 - accuracy\n",
      "3306/3306 [==============================] - 7s 2ms/step - loss: 0.6391 - accuracy: 0.6472\n",
      "3306/3306 [==============================] - 6s 2ms/step - loss: 0.6386 - accuracy: 0.6451\n",
      "3306/3306 [==============================] - 6s 2ms/step - loss: 0.6381 - accuracy: 0.6474\n",
      "3306/3306 [==============================] - 8s 2ms/step - loss: 0.6375 - accuracy: 0.6464\n",
      "3306/3306 [==============================] - 11s 3ms/step - loss: 0.6390 - accuracy: 0.6464\n",
      "3306/3306 [==============================] - 5s 2ms/step - loss: 0.6378 - accuracy: 0.6449\n",
      "   1/3306 [..............................] - ETA: 0s - loss: 0.7066 - accuracy: 0.5000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_train_batch_end` time: 0.0038s). Check your callbacks.\n",
      "3306/3306 [==============================] - 5s 2ms/step - loss: 0.6371 - accuracy: 0.6482\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6383 - accuracy: 0.6483\n",
      "3306/3306 [==============================] - 5s 2ms/step - loss: 0.6372 - accuracy: 0.6475\n",
      "3306/3306 [==============================] - 5s 2ms/step - loss: 0.6354 - accuracy: 0.6484\n",
      "3306/3306 [==============================] - 6s 2ms/step - loss: 0.6389 - accuracy: 0.6454\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6372 - accuracy: 0.6463\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6375 - accuracy: 0.6468\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6350 - accuracy: 0.6473\n",
      "3306/3306 [==============================] - 4s 1ms/step - loss: 0.6368 - accuracy: 0.6465\n",
      "3306/3306 [==============================] - 5s 2ms/step - loss: 0.6346 - accuracy: 0.6473\n",
      "3306/3306 [==============================] - 6s 2ms/step - loss: 0.6393 - accuracy: 0.6468\n",
      "3306/3306 [==============================] - 5s 2ms/step - loss: 0.6384 - accuracy: 0.6463\n",
      "3306/3306 [==============================] - 5s 2ms/step - loss: 0.6380 - accuracy: 0.6474\n",
      "3306/3306 [==============================] - 5s 2ms/step - loss: 0.6358 - accuracy: 0.6476\n",
      "3306/3306 [==============================] - 6s 2ms/step - loss: 0.6385 - accuracy: 0.6465\n",
      "3306/3306 [==============================] - 6s 2ms/step - loss: 0.6384 - accuracy: 0.6457\n",
      "3306/3306 [==============================] - 6s 2ms/step - loss: 0.6379 - accuracy: 0.6453\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6385 - accuracy: 0.6471\n",
      "3306/3306 [==============================] - 6s 2ms/step - loss: 0.6383 - accuracy: 0.6455\n",
      "3306/3306 [==============================] - 6s 2ms/step - loss: 0.6374 - accuracy: 0.6470\n",
      "3306/3306 [==============================] - 6s 2ms/step - loss: 0.6356 - accuracy: 0.6460\n",
      "3306/3306 [==============================] - 5s 2ms/step - loss: 0.6376 - accuracy: 0.6469\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6356 - accuracy: 0.6474: 0s - los\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6366 - accuracy: 0.6480: 0s - loss: 0.6371 - accura\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6387 - accuracy: 0.6474\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6397 - accuracy: 0.6468\n",
      "3306/3306 [==============================] - 5s 2ms/step - loss: 0.6367 - accuracy: 0.6472\n",
      "3306/3306 [==============================] - 5s 2ms/step - loss: 0.6359 - accuracy: 0.6478\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6389 - accuracy: 0.6462\n",
      "3306/3306 [==============================] - 6s 2ms/step - loss: 0.6367 - accuracy: 0.6474\n",
      "3306/3306 [==============================] - 5s 2ms/step - loss: 0.6376 - accuracy: 0.6451\n",
      "3306/3306 [==============================] - 7s 2ms/step - loss: 0.6384 - accuracy: 0.6479\n",
      "3306/3306 [==============================] - 5s 2ms/step - loss: 0.6370 - accuracy: 0.6465\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6375 - accuracy: 0.6476\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6390 - accuracy: 0.6466\n",
      "3306/3306 [==============================] - 4s 1ms/step - loss: 0.6366 - accuracy: 0.6454\n",
      "3306/3306 [==============================] - 4s 1ms/step - loss: 0.6378 - accuracy: 0.6464\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6374 - accuracy: 0.6468\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6366 - accuracy: 0.6447\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6371 - accuracy: 0.6477\n",
      "3306/3306 [==============================] - 5s 2ms/step - loss: 0.6357 - accuracy: 0.6478: 0s - loss: 0.6373 - accuracy: 0.64 - ETA: 0s - loss: 0.6372 \n",
      "3306/3306 [==============================] - 6s 2ms/step - loss: 0.6383 - accuracy: 0.6478\n",
      "3306/3306 [==============================] - 4s 1ms/step - loss: 0.6383 - accuracy: 0.6475\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6374 - accuracy: 0.6475\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6365 - accuracy: 0.6478\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6378 - accuracy: 0.6457\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6354 - accuracy: 0.6477\n",
      "3306/3306 [==============================] - 9s 3ms/step - loss: 0.6374 - accuracy: 0.6480\n",
      "3306/3306 [==============================] - 6s 2ms/step - loss: 0.6374 - accuracy: 0.6463\n",
      "3306/3306 [==============================] - 5s 2ms/step - loss: 0.6366 - accuracy: 0.6472: 0s - loss: 0.6368 - accuracy: 0.\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6382 - accuracy: 0.6466\n",
      "3306/3306 [==============================] - 4s 1ms/step - loss: 0.6372 - accuracy: 0.6478\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6358 - accuracy: 0.6472\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6368 - accuracy: 0.6469\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6378 - accuracy: 0.6462\n",
      "3306/3306 [==============================] - 4s 1ms/step - loss: 0.6391 - accuracy: 0.6460\n",
      "3306/3306 [==============================] - 6s 2ms/step - loss: 0.6393 - accuracy: 0.6473\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6382 - accuracy: 0.6462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6390 - accuracy: 0.6465\n",
      "3306/3306 [==============================] - 5s 1ms/step - loss: 0.6368 - accuracy: 0.6458\n",
      "2067/2067 [==============================] - 3s 2ms/step - loss: 0.6389 - accuracy: 0.6471\n",
      "2067/2067 [==============================] - 3s 2ms/step - loss: 0.6374 - accuracy: 0.6482\n",
      "2067/2067 [==============================] - 3s 2ms/step - loss: 0.6376 - accuracy: 0.6479\n",
      "2067/2067 [==============================] - 4s 2ms/step - loss: 0.6377 - accuracy: 0.6484\n",
      "2067/2067 [==============================] - 6s 3ms/step - loss: 0.6390 - accuracy: 0.6471\n",
      "2067/2067 [==============================] - 3s 2ms/step - loss: 0.6368 - accuracy: 0.6463\n",
      "2067/2067 [==============================] - 3s 1ms/step - loss: 0.6399 - accuracy: 0.6474\n",
      "2067/2067 [==============================] - 3s 1ms/step - loss: 0.6383 - accuracy: 0.6479\n",
      "2067/2067 [==============================] - 3s 2ms/step - loss: 0.6373 - accuracy: 0.6467\n",
      "2067/2067 [==============================] - 4s 2ms/step - loss: 0.6376 - accuracy: 0.6478\n",
      "2067/2067 [==============================] - 4s 2ms/step - loss: 0.6372 - accuracy: 0.6470\n",
      "2067/2067 [==============================] - 3s 1ms/step - loss: 0.6380 - accuracy: 0.6465\n",
      "2067/2067 [==============================] - 3s 1ms/step - loss: 0.6381 - accuracy: 0.6472\n",
      "2067/2067 [==============================] - 3s 1ms/step - loss: 0.6367 - accuracy: 0.6475\n",
      "2067/2067 [==============================] - 3s 1ms/step - loss: 0.6392 - accuracy: 0.6479\n",
      "2067/2067 [==============================] - 3s 1ms/step - loss: 0.6395 - accuracy: 0.6464\n",
      "2067/2067 [==============================] - 3s 1ms/step - loss: 0.6379 - accuracy: 0.6454\n",
      "2067/2067 [==============================] - 3s 1ms/step - loss: 0.6392 - accuracy: 0.6481\n",
      "2067/2067 [==============================] - 3s 1ms/step - loss: 0.6380 - accuracy: 0.6471\n",
      "2067/2067 [==============================] - 3s 1ms/step - loss: 0.6390 - accuracy: 0.6470\n",
      "2067/2067 [==============================] - 3s 1ms/step - loss: 0.6371 - accuracy: 0.6483\n",
      "2067/2067 [==============================] - 3s 1ms/step - loss: 0.6371 - accuracy: 0.6474\n",
      "2067/2067 [==============================] - 3s 2ms/step - loss: 0.6374 - accuracy: 0.6485\n",
      "2067/2067 [==============================] - 3s 2ms/step - loss: 0.6379 - accuracy: 0.6475\n",
      "2067/2067 [==============================] - 3s 2ms/step - loss: 0.6367 - accuracy: 0.6481\n",
      "2067/2067 [==============================] - 3s 2ms/step - loss: 0.6387 - accuracy: 0.6458\n",
      "2067/2067 [==============================] - 3s 2ms/step - loss: 0.6376 - accuracy: 0.6471\n"
     ]
    }
   ],
   "source": [
    "#we need to fit our training set.\n",
    "\n",
    "grid_search = grid_search.fit(X_train,y_train)\n",
    "\n",
    "#we get the best selection of parameters using best_params from the grid search object\n",
    "\n",
    "best_param = grid_search.best_params_\n",
    "\n",
    "#we get the best accuracy score using best_score_\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "#NB: this process will take a while\n",
    "\n",
    "best_param, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
