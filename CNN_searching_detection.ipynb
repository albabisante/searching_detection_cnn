{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_samples_from_csv(file_path, n_steps):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    df_final = df.drop(['Unnamed: 0'],axis=1) #'date','lat','lon'\n",
    "\n",
    "    df_final = df_final.to_numpy()\n",
    "    \n",
    "    X, y = split_sequences(df_final, n_steps)\n",
    "    \n",
    "    print(\"Downloading file\",file_path)\n",
    "    print(\"Input shape (samples, number of steps, features): \",array(X).shape)\n",
    "    print(\"Target shape (samples): \",array(y).shape)\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file dataset/CNN/not_searching/csv/1222.json.csv\n",
      "Input shape (samples, number of steps, features):  (209, 5, 7)\n",
      "Target shape (samples):  (209,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1254.json.csv\n",
      "Input shape (samples, number of steps, features):  (971, 5, 7)\n",
      "Target shape (samples):  (971,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1423.json.csv\n",
      "Input shape (samples, number of steps, features):  (271, 5, 7)\n",
      "Target shape (samples):  (271,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1536.json.csv\n",
      "Input shape (samples, number of steps, features):  (17, 5, 7)\n",
      "Target shape (samples):  (17,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1538.json.csv\n",
      "Input shape (samples, number of steps, features):  (794, 5, 7)\n",
      "Target shape (samples):  (794,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1546.json.csv\n",
      "Input shape (samples, number of steps, features):  (734, 5, 7)\n",
      "Target shape (samples):  (734,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1550.json.csv\n",
      "Input shape (samples, number of steps, features):  (355, 5, 7)\n",
      "Target shape (samples):  (355,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1552.json.csv\n",
      "Input shape (samples, number of steps, features):  (307, 5, 7)\n",
      "Target shape (samples):  (307,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1638.json.csv\n",
      "Input shape (samples, number of steps, features):  (732, 5, 7)\n",
      "Target shape (samples):  (732,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1645.json.csv\n",
      "Input shape (samples, number of steps, features):  (416, 5, 7)\n",
      "Target shape (samples):  (416,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1649.json.csv\n",
      "Input shape (samples, number of steps, features):  (489, 5, 7)\n",
      "Target shape (samples):  (489,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1673.json.csv\n",
      "Input shape (samples, number of steps, features):  (1640, 5, 7)\n",
      "Target shape (samples):  (1640,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1677.json.csv\n",
      "Input shape (samples, number of steps, features):  (772, 5, 7)\n",
      "Target shape (samples):  (772,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1683.json.csv\n",
      "Input shape (samples, number of steps, features):  (780, 5, 7)\n",
      "Target shape (samples):  (780,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1711.json.csv\n",
      "Input shape (samples, number of steps, features):  (164, 5, 7)\n",
      "Target shape (samples):  (164,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1755.json.csv\n",
      "Input shape (samples, number of steps, features):  (103, 5, 7)\n",
      "Target shape (samples):  (103,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1759.json.csv\n",
      "Input shape (samples, number of steps, features):  (142, 5, 7)\n",
      "Target shape (samples):  (142,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1761.json.csv\n",
      "Input shape (samples, number of steps, features):  (220, 5, 7)\n",
      "Target shape (samples):  (220,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1767.json.csv\n",
      "Input shape (samples, number of steps, features):  (381, 5, 7)\n",
      "Target shape (samples):  (381,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1769.json.csv\n",
      "Input shape (samples, number of steps, features):  (210, 5, 7)\n",
      "Target shape (samples):  (210,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1774.json.csv\n",
      "Input shape (samples, number of steps, features):  (1248, 5, 7)\n",
      "Target shape (samples):  (1248,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1802.json.csv\n",
      "Input shape (samples, number of steps, features):  (855, 5, 7)\n",
      "Target shape (samples):  (855,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1804.json.csv\n",
      "Input shape (samples, number of steps, features):  (228, 5, 7)\n",
      "Target shape (samples):  (228,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1817.json.csv\n",
      "Input shape (samples, number of steps, features):  (384, 5, 7)\n",
      "Target shape (samples):  (384,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1843.json.csv\n",
      "Input shape (samples, number of steps, features):  (129, 5, 7)\n",
      "Target shape (samples):  (129,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1860.json.csv\n",
      "Input shape (samples, number of steps, features):  (259, 5, 7)\n",
      "Target shape (samples):  (259,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1864.json.csv\n",
      "Input shape (samples, number of steps, features):  (211, 5, 7)\n",
      "Target shape (samples):  (211,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1866.json.csv\n",
      "Input shape (samples, number of steps, features):  (725, 5, 7)\n",
      "Target shape (samples):  (725,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1868.json.csv\n",
      "Input shape (samples, number of steps, features):  (248, 5, 7)\n",
      "Target shape (samples):  (248,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1870.json.csv\n",
      "Input shape (samples, number of steps, features):  (285, 5, 7)\n",
      "Target shape (samples):  (285,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1874.json.csv\n",
      "Input shape (samples, number of steps, features):  (411, 5, 7)\n",
      "Target shape (samples):  (411,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1876.json.csv\n",
      "Input shape (samples, number of steps, features):  (470, 5, 7)\n",
      "Target shape (samples):  (470,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1878.json.csv\n",
      "Input shape (samples, number of steps, features):  (254, 5, 7)\n",
      "Target shape (samples):  (254,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1880.json.csv\n",
      "Input shape (samples, number of steps, features):  (340, 5, 7)\n",
      "Target shape (samples):  (340,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1891.json.csv\n",
      "Input shape (samples, number of steps, features):  (496, 5, 7)\n",
      "Target shape (samples):  (496,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1948.json.csv\n",
      "Input shape (samples, number of steps, features):  (335, 5, 7)\n",
      "Target shape (samples):  (335,)\n",
      "Downloading file dataset/CNN/not_searching/csv/1959.json.csv\n",
      "Input shape (samples, number of steps, features):  (0,)\n",
      "Target shape (samples):  (0,)\n",
      "Downloading file dataset/CNN/not_searching/csv/2134.json.csv\n",
      "Input shape (samples, number of steps, features):  (1109, 5, 7)\n",
      "Target shape (samples):  (1109,)\n",
      "Downloading file dataset/CNN/not_searching/csv/2142.json.csv\n",
      "Input shape (samples, number of steps, features):  (818, 5, 7)\n",
      "Target shape (samples):  (818,)\n",
      "Downloading file dataset/CNN/not_searching/csv/2144.json.csv\n",
      "Input shape (samples, number of steps, features):  (277, 5, 7)\n",
      "Target shape (samples):  (277,)\n",
      "Downloading file dataset/CNN/not_searching/csv/2150.json.csv\n",
      "Input shape (samples, number of steps, features):  (484, 5, 7)\n",
      "Target shape (samples):  (484,)\n",
      "Downloading file dataset/CNN/not_searching/csv/2199.json.csv\n",
      "Input shape (samples, number of steps, features):  (529, 5, 7)\n",
      "Target shape (samples):  (529,)\n",
      "Downloading file dataset/CNN/not_searching/csv/2204.json.csv\n",
      "Input shape (samples, number of steps, features):  (181, 5, 7)\n",
      "Target shape (samples):  (181,)\n",
      "Downloading file dataset/CNN/not_searching/csv/2206.json.csv\n",
      "Input shape (samples, number of steps, features):  (843, 5, 7)\n",
      "Target shape (samples):  (843,)\n",
      "Downloading file dataset/CNN/not_searching/csv/2311.json.csv\n",
      "Input shape (samples, number of steps, features):  (383, 5, 7)\n",
      "Target shape (samples):  (383,)\n",
      "Downloading file dataset/CNN/not_searching/csv/2489.json.csv\n",
      "Input shape (samples, number of steps, features):  (421, 5, 7)\n",
      "Target shape (samples):  (421,)\n",
      "Downloading file dataset/CNN/not_searching/csv/2603.json.csv\n",
      "Input shape (samples, number of steps, features):  (0,)\n",
      "Target shape (samples):  (0,)\n",
      "Downloading file dataset/CNN/not_searching/csv/2675.json.csv\n",
      "Input shape (samples, number of steps, features):  (703, 5, 7)\n",
      "Target shape (samples):  (703,)\n",
      "Downloading file dataset/CNN/not_searching/csv/2715.json.csv\n",
      "Input shape (samples, number of steps, features):  (793, 5, 7)\n",
      "Target shape (samples):  (793,)\n",
      "Downloading file dataset/CNN/not_searching/csv/2718.json.csv\n",
      "Input shape (samples, number of steps, features):  (534, 5, 7)\n",
      "Target shape (samples):  (534,)\n",
      "Downloading file dataset/CNN/not_searching/csv/3196.json.csv\n",
      "Input shape (samples, number of steps, features):  (357, 5, 7)\n",
      "Target shape (samples):  (357,)\n",
      "Downloading file dataset/CNN/not_searching/csv/3207.json.csv\n",
      "Input shape (samples, number of steps, features):  (159, 5, 7)\n",
      "Target shape (samples):  (159,)\n",
      "Downloading file dataset/CNN/not_searching/csv/3347.json.csv\n",
      "Input shape (samples, number of steps, features):  (602, 5, 7)\n",
      "Target shape (samples):  (602,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file dataset/CNN/not_searching/csv/3491.json.csv\n",
      "Input shape (samples, number of steps, features):  (1185, 5, 7)\n",
      "Target shape (samples):  (1185,)\n",
      "Downloading file dataset/CNN/not_searching/csv/3513.json.csv\n",
      "Input shape (samples, number of steps, features):  (1150, 5, 7)\n",
      "Target shape (samples):  (1150,)\n",
      "Downloading file dataset/CNN/not_searching/csv/3633.json.csv\n",
      "Input shape (samples, number of steps, features):  (939, 5, 7)\n",
      "Target shape (samples):  (939,)\n",
      "Downloading file dataset/CNN/not_searching/csv/3671.json.csv\n",
      "Input shape (samples, number of steps, features):  (594, 5, 7)\n",
      "Target shape (samples):  (594,)\n",
      "Downloading file dataset/CNN/not_searching/csv/4002.json.csv\n",
      "Input shape (samples, number of steps, features):  (0,)\n",
      "Target shape (samples):  (0,)\n",
      "Downloading file dataset/CNN/not_searching/csv/4076.json.csv\n",
      "Input shape (samples, number of steps, features):  (654, 5, 7)\n",
      "Target shape (samples):  (654,)\n",
      "Downloading file dataset/CNN/not_searching/csv/4488.json.csv\n",
      "Input shape (samples, number of steps, features):  (784, 5, 7)\n",
      "Target shape (samples):  (784,)\n",
      "Downloading file dataset/CNN/not_searching/csv/4505.json.csv\n",
      "Input shape (samples, number of steps, features):  (1192, 5, 7)\n",
      "Target shape (samples):  (1192,)\n",
      "Downloading file dataset/CNN/not_searching/csv/4849.json.csv\n",
      "Input shape (samples, number of steps, features):  (925, 5, 7)\n",
      "Target shape (samples):  (925,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5397.json.csv\n",
      "Input shape (samples, number of steps, features):  (887, 5, 7)\n",
      "Target shape (samples):  (887,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5417.json.csv\n",
      "Input shape (samples, number of steps, features):  (916, 5, 7)\n",
      "Target shape (samples):  (916,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5419.json.csv\n",
      "Input shape (samples, number of steps, features):  (436, 5, 7)\n",
      "Target shape (samples):  (436,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5421.json.csv\n",
      "Input shape (samples, number of steps, features):  (387, 5, 7)\n",
      "Target shape (samples):  (387,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5443.json.csv\n",
      "Input shape (samples, number of steps, features):  (231, 5, 7)\n",
      "Target shape (samples):  (231,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5470.json.csv\n",
      "Input shape (samples, number of steps, features):  (804, 5, 7)\n",
      "Target shape (samples):  (804,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5474.json.csv\n",
      "Input shape (samples, number of steps, features):  (298, 5, 7)\n",
      "Target shape (samples):  (298,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5516.json.csv\n",
      "Input shape (samples, number of steps, features):  (649, 5, 7)\n",
      "Target shape (samples):  (649,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5518.json.csv\n",
      "Input shape (samples, number of steps, features):  (404, 5, 7)\n",
      "Target shape (samples):  (404,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5525.json.csv\n",
      "Input shape (samples, number of steps, features):  (560, 5, 7)\n",
      "Target shape (samples):  (560,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5529.json.csv\n",
      "Input shape (samples, number of steps, features):  (733, 5, 7)\n",
      "Target shape (samples):  (733,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5607.json.csv\n",
      "Input shape (samples, number of steps, features):  (540, 5, 7)\n",
      "Target shape (samples):  (540,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5617.json.csv\n",
      "Input shape (samples, number of steps, features):  (998, 5, 7)\n",
      "Target shape (samples):  (998,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5649.json.csv\n",
      "Input shape (samples, number of steps, features):  (669, 5, 7)\n",
      "Target shape (samples):  (669,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5656.json.csv\n",
      "Input shape (samples, number of steps, features):  (1079, 5, 7)\n",
      "Target shape (samples):  (1079,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5658.json.csv\n",
      "Input shape (samples, number of steps, features):  (1984, 5, 7)\n",
      "Target shape (samples):  (1984,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5666.json.csv\n",
      "Input shape (samples, number of steps, features):  (667, 5, 7)\n",
      "Target shape (samples):  (667,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5779.json.csv\n",
      "Input shape (samples, number of steps, features):  (659, 5, 7)\n",
      "Target shape (samples):  (659,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5920.json.csv\n",
      "Input shape (samples, number of steps, features):  (568, 5, 7)\n",
      "Target shape (samples):  (568,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5939.json.csv\n",
      "Input shape (samples, number of steps, features):  (42, 5, 7)\n",
      "Target shape (samples):  (42,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5945.json.csv\n",
      "Input shape (samples, number of steps, features):  (1070, 5, 7)\n",
      "Target shape (samples):  (1070,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5951.json.csv\n",
      "Input shape (samples, number of steps, features):  (661, 5, 7)\n",
      "Target shape (samples):  (661,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5957.json.csv\n",
      "Input shape (samples, number of steps, features):  (996, 5, 7)\n",
      "Target shape (samples):  (996,)\n",
      "Downloading file dataset/CNN/not_searching/csv/5980.json.csv\n",
      "Input shape (samples, number of steps, features):  (530, 5, 7)\n",
      "Target shape (samples):  (530,)\n",
      "Downloading file dataset/CNN/not_searching/csv/6013.json.csv\n",
      "Input shape (samples, number of steps, features):  (836, 5, 7)\n",
      "Target shape (samples):  (836,)\n",
      "Downloading file dataset/CNN/not_searching/csv/6022.json.csv\n",
      "Input shape (samples, number of steps, features):  (1641, 5, 7)\n",
      "Target shape (samples):  (1641,)\n",
      "Downloading file dataset/CNN/not_searching/csv/6024.json.csv\n",
      "Input shape (samples, number of steps, features):  (673, 5, 7)\n",
      "Target shape (samples):  (673,)\n",
      "Downloading file dataset/CNN/not_searching/csv/6028.json.csv\n",
      "Input shape (samples, number of steps, features):  (847, 5, 7)\n",
      "Target shape (samples):  (847,)\n",
      "Downloading file dataset/CNN/searching/csv/1222.json.csv\n",
      "Input shape (samples, number of steps, features):  (187, 5, 7)\n",
      "Target shape (samples):  (187,)\n",
      "Downloading file dataset/CNN/searching/csv/1254.json.csv\n",
      "Input shape (samples, number of steps, features):  (465, 5, 7)\n",
      "Target shape (samples):  (465,)\n",
      "Downloading file dataset/CNN/searching/csv/1423.json.csv\n",
      "Input shape (samples, number of steps, features):  (273, 5, 7)\n",
      "Target shape (samples):  (273,)\n",
      "Downloading file dataset/CNN/searching/csv/1536.json.csv\n",
      "Input shape (samples, number of steps, features):  (0,)\n",
      "Target shape (samples):  (0,)\n",
      "Downloading file dataset/CNN/searching/csv/1538.json.csv\n",
      "Input shape (samples, number of steps, features):  (96, 5, 7)\n",
      "Target shape (samples):  (96,)\n",
      "Downloading file dataset/CNN/searching/csv/1546.json.csv\n",
      "Input shape (samples, number of steps, features):  (255, 5, 7)\n",
      "Target shape (samples):  (255,)\n",
      "Downloading file dataset/CNN/searching/csv/1550.json.csv\n",
      "Input shape (samples, number of steps, features):  (224, 5, 7)\n",
      "Target shape (samples):  (224,)\n",
      "Downloading file dataset/CNN/searching/csv/1552.json.csv\n",
      "Input shape (samples, number of steps, features):  (431, 5, 7)\n",
      "Target shape (samples):  (431,)\n",
      "Downloading file dataset/CNN/searching/csv/1638.json.csv\n",
      "Input shape (samples, number of steps, features):  (312, 5, 7)\n",
      "Target shape (samples):  (312,)\n",
      "Downloading file dataset/CNN/searching/csv/1645.json.csv\n",
      "Input shape (samples, number of steps, features):  (249, 5, 7)\n",
      "Target shape (samples):  (249,)\n",
      "Downloading file dataset/CNN/searching/csv/1649.json.csv\n",
      "Input shape (samples, number of steps, features):  (369, 5, 7)\n",
      "Target shape (samples):  (369,)\n",
      "Downloading file dataset/CNN/searching/csv/1673.json.csv\n",
      "Input shape (samples, number of steps, features):  (301, 5, 7)\n",
      "Target shape (samples):  (301,)\n",
      "Downloading file dataset/CNN/searching/csv/1677.json.csv\n",
      "Input shape (samples, number of steps, features):  (205, 5, 7)\n",
      "Target shape (samples):  (205,)\n",
      "Downloading file dataset/CNN/searching/csv/1683.json.csv\n",
      "Input shape (samples, number of steps, features):  (392, 5, 7)\n",
      "Target shape (samples):  (392,)\n",
      "Downloading file dataset/CNN/searching/csv/1711.json.csv\n",
      "Input shape (samples, number of steps, features):  (136, 5, 7)\n",
      "Target shape (samples):  (136,)\n",
      "Downloading file dataset/CNN/searching/csv/1755.json.csv\n",
      "Input shape (samples, number of steps, features):  (143, 5, 7)\n",
      "Target shape (samples):  (143,)\n",
      "Downloading file dataset/CNN/searching/csv/1759.json.csv\n",
      "Input shape (samples, number of steps, features):  (199, 5, 7)\n",
      "Target shape (samples):  (199,)\n",
      "Downloading file dataset/CNN/searching/csv/1761.json.csv\n",
      "Input shape (samples, number of steps, features):  (266, 5, 7)\n",
      "Target shape (samples):  (266,)\n",
      "Downloading file dataset/CNN/searching/csv/1767.json.csv\n",
      "Input shape (samples, number of steps, features):  (221, 5, 7)\n",
      "Target shape (samples):  (221,)\n",
      "Downloading file dataset/CNN/searching/csv/1769.json.csv\n",
      "Input shape (samples, number of steps, features):  (441, 5, 7)\n",
      "Target shape (samples):  (441,)\n",
      "Downloading file dataset/CNN/searching/csv/1774.json.csv\n",
      "Input shape (samples, number of steps, features):  (218, 5, 7)\n",
      "Target shape (samples):  (218,)\n",
      "Downloading file dataset/CNN/searching/csv/1802.json.csv\n",
      "Input shape (samples, number of steps, features):  (303, 5, 7)\n",
      "Target shape (samples):  (303,)\n",
      "Downloading file dataset/CNN/searching/csv/1804.json.csv\n",
      "Input shape (samples, number of steps, features):  (266, 5, 7)\n",
      "Target shape (samples):  (266,)\n",
      "Downloading file dataset/CNN/searching/csv/1817.json.csv\n",
      "Input shape (samples, number of steps, features):  (178, 5, 7)\n",
      "Target shape (samples):  (178,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file dataset/CNN/searching/csv/1843.json.csv\n",
      "Input shape (samples, number of steps, features):  (172, 5, 7)\n",
      "Target shape (samples):  (172,)\n",
      "Downloading file dataset/CNN/searching/csv/1860.json.csv\n",
      "Input shape (samples, number of steps, features):  (375, 5, 7)\n",
      "Target shape (samples):  (375,)\n",
      "Downloading file dataset/CNN/searching/csv/1864.json.csv\n",
      "Input shape (samples, number of steps, features):  (310, 5, 7)\n",
      "Target shape (samples):  (310,)\n",
      "Downloading file dataset/CNN/searching/csv/1866.json.csv\n",
      "Input shape (samples, number of steps, features):  (88, 5, 7)\n",
      "Target shape (samples):  (88,)\n",
      "Downloading file dataset/CNN/searching/csv/1868.json.csv\n",
      "Input shape (samples, number of steps, features):  (477, 5, 7)\n",
      "Target shape (samples):  (477,)\n",
      "Downloading file dataset/CNN/searching/csv/1870.json.csv\n",
      "Input shape (samples, number of steps, features):  (157, 5, 7)\n",
      "Target shape (samples):  (157,)\n",
      "Downloading file dataset/CNN/searching/csv/1874.json.csv\n",
      "Input shape (samples, number of steps, features):  (994, 5, 7)\n",
      "Target shape (samples):  (994,)\n",
      "Downloading file dataset/CNN/searching/csv/1876.json.csv\n",
      "Input shape (samples, number of steps, features):  (197, 5, 7)\n",
      "Target shape (samples):  (197,)\n",
      "Downloading file dataset/CNN/searching/csv/1878.json.csv\n",
      "Input shape (samples, number of steps, features):  (260, 5, 7)\n",
      "Target shape (samples):  (260,)\n",
      "Downloading file dataset/CNN/searching/csv/1880.json.csv\n",
      "Input shape (samples, number of steps, features):  (292, 5, 7)\n",
      "Target shape (samples):  (292,)\n",
      "Downloading file dataset/CNN/searching/csv/1891.json.csv\n",
      "Input shape (samples, number of steps, features):  (65, 5, 7)\n",
      "Target shape (samples):  (65,)\n",
      "Downloading file dataset/CNN/searching/csv/1948.json.csv\n",
      "Input shape (samples, number of steps, features):  (353, 5, 7)\n",
      "Target shape (samples):  (353,)\n",
      "Downloading file dataset/CNN/searching/csv/1959.json.csv\n",
      "Input shape (samples, number of steps, features):  (833, 5, 7)\n",
      "Target shape (samples):  (833,)\n",
      "Downloading file dataset/CNN/searching/csv/2134.json.csv\n",
      "Input shape (samples, number of steps, features):  (269, 5, 7)\n",
      "Target shape (samples):  (269,)\n",
      "Downloading file dataset/CNN/searching/csv/2142.json.csv\n",
      "Input shape (samples, number of steps, features):  (251, 5, 7)\n",
      "Target shape (samples):  (251,)\n",
      "Downloading file dataset/CNN/searching/csv/2144.json.csv\n",
      "Input shape (samples, number of steps, features):  (475, 5, 7)\n",
      "Target shape (samples):  (475,)\n",
      "Downloading file dataset/CNN/searching/csv/2150.json.csv\n",
      "Input shape (samples, number of steps, features):  (256, 5, 7)\n",
      "Target shape (samples):  (256,)\n",
      "Downloading file dataset/CNN/searching/csv/2199.json.csv\n",
      "Input shape (samples, number of steps, features):  (776, 5, 7)\n",
      "Target shape (samples):  (776,)\n",
      "Downloading file dataset/CNN/searching/csv/2204.json.csv\n",
      "Input shape (samples, number of steps, features):  (179, 5, 7)\n",
      "Target shape (samples):  (179,)\n",
      "Downloading file dataset/CNN/searching/csv/2206.json.csv\n",
      "Input shape (samples, number of steps, features):  (227, 5, 7)\n",
      "Target shape (samples):  (227,)\n",
      "Downloading file dataset/CNN/searching/csv/2311.json.csv\n",
      "Input shape (samples, number of steps, features):  (384, 5, 7)\n",
      "Target shape (samples):  (384,)\n",
      "Downloading file dataset/CNN/searching/csv/2489.json.csv\n",
      "Input shape (samples, number of steps, features):  (145, 5, 7)\n",
      "Target shape (samples):  (145,)\n",
      "Downloading file dataset/CNN/searching/csv/2603.json.csv\n",
      "Input shape (samples, number of steps, features):  (383, 5, 7)\n",
      "Target shape (samples):  (383,)\n",
      "Downloading file dataset/CNN/searching/csv/2675.json.csv\n",
      "Input shape (samples, number of steps, features):  (261, 5, 7)\n",
      "Target shape (samples):  (261,)\n",
      "Downloading file dataset/CNN/searching/csv/2715.json.csv\n",
      "Input shape (samples, number of steps, features):  (164, 5, 7)\n",
      "Target shape (samples):  (164,)\n",
      "Downloading file dataset/CNN/searching/csv/2718.json.csv\n",
      "Input shape (samples, number of steps, features):  (333, 5, 7)\n",
      "Target shape (samples):  (333,)\n",
      "Downloading file dataset/CNN/searching/csv/3196.json.csv\n",
      "Input shape (samples, number of steps, features):  (34, 5, 7)\n",
      "Target shape (samples):  (34,)\n",
      "Downloading file dataset/CNN/searching/csv/3207.json.csv\n",
      "Input shape (samples, number of steps, features):  (241, 5, 7)\n",
      "Target shape (samples):  (241,)\n",
      "Downloading file dataset/CNN/searching/csv/3347.json.csv\n",
      "Input shape (samples, number of steps, features):  (146, 5, 7)\n",
      "Target shape (samples):  (146,)\n",
      "Downloading file dataset/CNN/searching/csv/3491.json.csv\n",
      "Input shape (samples, number of steps, features):  (332, 5, 7)\n",
      "Target shape (samples):  (332,)\n",
      "Downloading file dataset/CNN/searching/csv/3513.json.csv\n",
      "Input shape (samples, number of steps, features):  (134, 5, 7)\n",
      "Target shape (samples):  (134,)\n",
      "Downloading file dataset/CNN/searching/csv/3633.json.csv\n",
      "Input shape (samples, number of steps, features):  (294, 5, 7)\n",
      "Target shape (samples):  (294,)\n",
      "Downloading file dataset/CNN/searching/csv/3671.json.csv\n",
      "Input shape (samples, number of steps, features):  (220, 5, 7)\n",
      "Target shape (samples):  (220,)\n",
      "Downloading file dataset/CNN/searching/csv/4002.json.csv\n",
      "Input shape (samples, number of steps, features):  (321, 5, 7)\n",
      "Target shape (samples):  (321,)\n",
      "Downloading file dataset/CNN/searching/csv/4076.json.csv\n",
      "Input shape (samples, number of steps, features):  (705, 5, 7)\n",
      "Target shape (samples):  (705,)\n",
      "Downloading file dataset/CNN/searching/csv/4488.json.csv\n",
      "Input shape (samples, number of steps, features):  (305, 5, 7)\n",
      "Target shape (samples):  (305,)\n",
      "Downloading file dataset/CNN/searching/csv/4505.json.csv\n",
      "Input shape (samples, number of steps, features):  (482, 5, 7)\n",
      "Target shape (samples):  (482,)\n",
      "Downloading file dataset/CNN/searching/csv/4849.json.csv\n",
      "Input shape (samples, number of steps, features):  (217, 5, 7)\n",
      "Target shape (samples):  (217,)\n",
      "Downloading file dataset/CNN/searching/csv/5397.json.csv\n",
      "Input shape (samples, number of steps, features):  (1021, 5, 7)\n",
      "Target shape (samples):  (1021,)\n",
      "Downloading file dataset/CNN/searching/csv/5417.json.csv\n",
      "Input shape (samples, number of steps, features):  (237, 5, 7)\n",
      "Target shape (samples):  (237,)\n",
      "Downloading file dataset/CNN/searching/csv/5419.json.csv\n",
      "Input shape (samples, number of steps, features):  (359, 5, 7)\n",
      "Target shape (samples):  (359,)\n",
      "Downloading file dataset/CNN/searching/csv/5421.json.csv\n",
      "Input shape (samples, number of steps, features):  (425, 5, 7)\n",
      "Target shape (samples):  (425,)\n",
      "Downloading file dataset/CNN/searching/csv/5443.json.csv\n",
      "Input shape (samples, number of steps, features):  (348, 5, 7)\n",
      "Target shape (samples):  (348,)\n",
      "Downloading file dataset/CNN/searching/csv/5470.json.csv\n",
      "Input shape (samples, number of steps, features):  (52, 5, 7)\n",
      "Target shape (samples):  (52,)\n",
      "Downloading file dataset/CNN/searching/csv/5474.json.csv\n",
      "Input shape (samples, number of steps, features):  (372, 5, 7)\n",
      "Target shape (samples):  (372,)\n",
      "Downloading file dataset/CNN/searching/csv/5516.json.csv\n",
      "Input shape (samples, number of steps, features):  (515, 5, 7)\n",
      "Target shape (samples):  (515,)\n",
      "Downloading file dataset/CNN/searching/csv/5518.json.csv\n",
      "Input shape (samples, number of steps, features):  (185, 5, 7)\n",
      "Target shape (samples):  (185,)\n",
      "Downloading file dataset/CNN/searching/csv/5525.json.csv\n",
      "Input shape (samples, number of steps, features):  (190, 5, 7)\n",
      "Target shape (samples):  (190,)\n",
      "Downloading file dataset/CNN/searching/csv/5529.json.csv\n",
      "Input shape (samples, number of steps, features):  (49, 5, 7)\n",
      "Target shape (samples):  (49,)\n",
      "Downloading file dataset/CNN/searching/csv/5607.json.csv\n",
      "Input shape (samples, number of steps, features):  (379, 5, 7)\n",
      "Target shape (samples):  (379,)\n",
      "Downloading file dataset/CNN/searching/csv/5617.json.csv\n",
      "Input shape (samples, number of steps, features):  (289, 5, 7)\n",
      "Target shape (samples):  (289,)\n",
      "Downloading file dataset/CNN/searching/csv/5649.json.csv\n",
      "Input shape (samples, number of steps, features):  (755, 5, 7)\n",
      "Target shape (samples):  (755,)\n",
      "Downloading file dataset/CNN/searching/csv/5656.json.csv\n",
      "Input shape (samples, number of steps, features):  (174, 5, 7)\n",
      "Target shape (samples):  (174,)\n",
      "Downloading file dataset/CNN/searching/csv/5658.json.csv\n",
      "Input shape (samples, number of steps, features):  (369, 5, 7)\n",
      "Target shape (samples):  (369,)\n",
      "Downloading file dataset/CNN/searching/csv/5666.json.csv\n",
      "Input shape (samples, number of steps, features):  (50, 5, 7)\n",
      "Target shape (samples):  (50,)\n",
      "Downloading file dataset/CNN/searching/csv/5779.json.csv\n",
      "Input shape (samples, number of steps, features):  (392, 5, 7)\n",
      "Target shape (samples):  (392,)\n",
      "Downloading file dataset/CNN/searching/csv/5920.json.csv\n",
      "Input shape (samples, number of steps, features):  (337, 5, 7)\n",
      "Target shape (samples):  (337,)\n",
      "Downloading file dataset/CNN/searching/csv/5939.json.csv\n",
      "Input shape (samples, number of steps, features):  (215, 5, 7)\n",
      "Target shape (samples):  (215,)\n",
      "Downloading file dataset/CNN/searching/csv/5945.json.csv\n",
      "Input shape (samples, number of steps, features):  (1406, 5, 7)\n",
      "Target shape (samples):  (1406,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file dataset/CNN/searching/csv/5951.json.csv\n",
      "Input shape (samples, number of steps, features):  (559, 5, 7)\n",
      "Target shape (samples):  (559,)\n",
      "Downloading file dataset/CNN/searching/csv/5957.json.csv\n",
      "Input shape (samples, number of steps, features):  (304, 5, 7)\n",
      "Target shape (samples):  (304,)\n",
      "Downloading file dataset/CNN/searching/csv/5980.json.csv\n",
      "Input shape (samples, number of steps, features):  (203, 5, 7)\n",
      "Target shape (samples):  (203,)\n",
      "Downloading file dataset/CNN/searching/csv/6013.json.csv\n",
      "Input shape (samples, number of steps, features):  (374, 5, 7)\n",
      "Target shape (samples):  (374,)\n",
      "Downloading file dataset/CNN/searching/csv/6022.json.csv\n",
      "Input shape (samples, number of steps, features):  (237, 5, 7)\n",
      "Target shape (samples):  (237,)\n",
      "Downloading file dataset/CNN/searching/csv/6024.json.csv\n",
      "Input shape (samples, number of steps, features):  (415, 5, 7)\n",
      "Target shape (samples):  (415,)\n",
      "Downloading file dataset/CNN/searching/csv/6028.json.csv\n",
      "Input shape (samples, number of steps, features):  (226, 5, 7)\n",
      "Target shape (samples):  (226,)\n",
      "Final dataset:  (81640, 5, 7) (81640,)\n",
      "Number of features:  7\n"
     ]
    }
   ],
   "source": [
    "#Choose time interval\n",
    "n_steps = 5\n",
    "samples_X = []\n",
    "samples_y = []\n",
    "\n",
    "\n",
    "dataset_path = \"dataset/CNN/\"\n",
    "\n",
    "not_searching_trips = sorted(os.listdir(dataset_path+\"not_searching/csv\"))\n",
    "for trip in not_searching_trips:\n",
    "    X, y = retrieve_samples_from_csv(dataset_path+\"not_searching/csv/\"+trip, n_steps)\n",
    "    samples_X += X\n",
    "    samples_y += y\n",
    "\n",
    "searching_trips = sorted(os.listdir(dataset_path+\"searching/csv\"))\n",
    "for trip in searching_trips:\n",
    "    X, y = retrieve_samples_from_csv(dataset_path+\"searching/csv/\"+trip, n_steps)\n",
    "    samples_X += X\n",
    "    samples_y += y\n",
    "\n",
    "X = array(samples_X)\n",
    "y = array(samples_y)\n",
    "\n",
    "\n",
    "'''\n",
    "dataset_path = \"dataset/ANN/\"\n",
    "X, y =  retrieve_samples_from_csv(dataset_path+\"training.csv\", n_steps)\n",
    "X = array(X)\n",
    "y = array(y)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# the dataset knows the number of features, e.g. 2\n",
    "n_features = X.shape[2]\n",
    "\n",
    "print(\"Final dataset: \", X.shape, y.shape)\n",
    "print(\"Number of features: \", n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57148, 5, 7) (24492, 5, 7)\n"
     ]
    }
   ],
   "source": [
    "#We then split the data into a training and test set. We use 0.7 of the data for training and 0.3 for testing.\n",
    "\n",
    "#X_train represents the independent variables we’re using to train\n",
    "#y_train represents the column we’re predicting\n",
    "\n",
    "#X_test represents the independent variables we’re using to test\n",
    "#y_test represents the column we’re predicting during tests\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "#Feature scaling standardizes the range of our independent variables.\n",
    "sc = StandardScaler()\n",
    "X_train =  TimeSeriesScalerMeanVariance(mu=0.,std=1.).fit_transform(X_train)\n",
    "X_test = TimeSeriesScalerMeanVariance(mu=0.,std=1.).fit_transform(X_test)\n",
    "#X_train = sc.transform(X_train)\n",
    "#X_test = sc.transform(X_test)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "#model.add(Dense(1))\n",
    "model.compile(optimizer= 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "#model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "BATCH_SIZE = 35\n",
    "EPOCHS = 30\n",
    "\n",
    "\n",
    "# fit model\n",
    "#history = model.fit(X_train, y_train, validation_split=0.3, batch_size=BATCH_SIZE,epochs=EPOCHS, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx_input = array([[5.78000020980835,0,21,0.0032495404551960002], [6.829999923706055,0,22,0.0032555182901280004], \\n                 [7.369999885559082,0,23,0.0032618821052950004], [8.170000076293945,0,24,0.0032689651254700003],\\n                 [8.170000076293945,0,0,0.0032689651254700003]\\n                ])\\n\\nx_input = sc.fit_transform(x_input)\\nprint(x_input)\\nx_input = x_input.reshape(1, n_steps, n_features)\\nyhat = model.predict(x_input, verbose=0)\\n\\nprint(yhat)\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediction example\n",
    "'''\n",
    "x_input = array([[5.78000020980835,0,21,0.0032495404551960002], [6.829999923706055,0,22,0.0032555182901280004], \n",
    "                 [7.369999885559082,0,23,0.0032618821052950004], [8.170000076293945,0,24,0.0032689651254700003],\n",
    "                 [8.170000076293945,0,0,0.0032689651254700003]\n",
    "                ])\n",
    "\n",
    "x_input = sc.fit_transform(x_input)\n",
    "print(x_input)\n",
    "x_input = x_input.reshape(1, n_steps, n_features)\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "\n",
    "print(yhat)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classifier():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps, n_features)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    #model.add(Dense(1))\n",
    "    model.compile(optimizer= 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 890/1143 [======================>.......] - ETA: 0s - loss: 0.6352 - accuracy: 0.6535"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-c10af9e98748>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m history = classifier.fit(X_train, y_train, validation_split=0.3, batch_size=BATCH_SIZE,\n\u001b[0;32m----> 4\u001b[0;31m                       epochs=EPOCHS, verbose=1)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(build_fn = make_classifier)\n",
    "\n",
    "history = classifier.fit(X_train, y_train, validation_split=0.3, batch_size=BATCH_SIZE,\n",
    "                      epochs=EPOCHS, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "[[False]\n",
      " [False]\n",
      " [False]\n",
      " ...\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n"
     ]
    }
   ],
   "source": [
    "#Predicting using the training set\n",
    "\n",
    "#This will show us the probability of a searching status.\n",
    "#We then set a threshold of 50% for classifying a status as 'searching'.\n",
    "#Any status with a probability of 0.5 or more will be classified as 'searching'.\n",
    "\n",
    "y_pred = classifier.predict(X_test).astype(\"int32\")\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14367,  1544],\n",
       "       [ 6723,  2070]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy and loss\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['accuracy'], \"g--\", label=\"Accuracy of training data\")\n",
    "plt.plot(history.history['val_accuracy'], \"g\", label=\"Accuracy of validation data\")\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Training Epoch')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0,1])\n",
    "plt.ylim(0)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# summarize history for accuracy and loss\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], \"r--\", label=\"Loss of training data\")\n",
    "plt.plot(history.history['val_loss'], \"r\", label=\"Loss of validation data\")\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.ylim(0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65371269, 0.66932684, 0.66013187, 0.65579456, 0.6370576 ,\n",
       "       0.66498959, 0.65666205, 0.66308117, 0.65562111, 0.65874392])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = cross_val_score(estimator = classifier,\n",
    "                             X = X_train,\n",
    "                             y = y_train,\n",
    "                             cv = 10,\n",
    "                            n_jobs = -1)\n",
    "\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6575121402740478, 6.749664588511451e-05)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To obtain the relative accuracies we get the mean of the accuracies.\n",
    "\n",
    "mean = accuracies.mean()\n",
    "\n",
    "#Then the variance.\n",
    "\n",
    "variance = accuracies.var()\n",
    "\n",
    "#Goal: to have a small variance between the accuracies.\n",
    "\n",
    "mean, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We’ll still use the KerasClassifier, \n",
    "#but we won’t pass the batch size and number of epochs \n",
    "#since these are the parameters we want to tune.\n",
    "\n",
    "classifier = KerasClassifier(build_fn = make_classifier)\n",
    "\n",
    "#Create a dictionary with the parameters we’d like to tune \n",
    "\n",
    "params = {\n",
    "    'batch_size':[20,32,35],\n",
    "    'nb_epoch':[50,100,150],\n",
    "    'optimizer':['adam','rmsprop']\n",
    "}\n",
    "\n",
    "#We then use Grid Search to test these parameters.\n",
    "#It expects our estimator, the parameters we just defined, the scoring metric and the number of k-folds.\n",
    "\n",
    "grid_search = GridSearchCV(estimator=classifier,\n",
    "                           param_grid=params,\n",
    "                           scoring='accuracy',\n",
    "                           cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6411 - accuracy: 0.6468\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6398 - accuracy: 0.6476\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6408 - accuracy: 0.6480\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6419 - accuracy: 0.6458\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6400 - accuracy: 0.6478\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6401 - accuracy: 0.6477\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6407 - accuracy: 0.6479\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6398 - accuracy: 0.6470\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6397 - accuracy: 0.6468\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6409 - accuracy: 0.6473\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6418 - accuracy: 0.6474\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6408 - accuracy: 0.6474\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6402 - accuracy: 0.6477\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6421 - accuracy: 0.6457\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6414 - accuracy: 0.6473\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6412 - accuracy: 0.6475\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6409 - accuracy: 0.6482\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6403 - accuracy: 0.6471\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6427 - accuracy: 0.6467\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6415 - accuracy: 0.6468\n",
      "2952/2952 [==============================] - 5s 2ms/step - loss: 0.6404 - accuracy: 0.6478\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6397 - accuracy: 0.6476\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6388 - accuracy: 0.6478\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6395 - accuracy: 0.6465\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6407 - accuracy: 0.6478\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6406 - accuracy: 0.6472\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6396 - accuracy: 0.6484\n",
      "2952/2952 [==============================] - 5s 2ms/step - loss: 0.6409 - accuracy: 0.6471\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6418 - accuracy: 0.6469\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6403 - accuracy: 0.6475\n",
      "2952/2952 [==============================] - 5s 2ms/step - loss: 0.6401 - accuracy: 0.6479\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6405 - accuracy: 0.6476\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6402 - accuracy: 0.6478\n",
      "2952/2952 [==============================] - 4s 2ms/step - loss: 0.6410 - accuracy: 0.6459\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6419 - accuracy: 0.6471\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6410 - accuracy: 0.6477\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6411 - accuracy: 0.6478\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6411 - accuracy: 0.6464\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6415 - accuracy: 0.6472: 0s - loss: 0.6\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6408 - accuracy: 0.6470\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6401 - accuracy: 0.6473\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6389 - accuracy: 0.6479\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6401 - accuracy: 0.6470\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6413 - accuracy: 0.6466\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6414 - accuracy: 0.6477\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6397 - accuracy: 0.6472\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6401 - accuracy: 0.6478\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6410 - accuracy: 0.6477: 0s - loss: 0.6417 - accura\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6416 - accuracy: 0.6466\n",
      "2952/2952 [==============================] - 4s 2ms/step - loss: 0.6418 - accuracy: 0.6469\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6426 - accuracy: 0.6473\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6410 - accuracy: 0.6475\n",
      "2952/2952 [==============================] - 5s 2ms/step - loss: 0.6407 - accuracy: 0.6473\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6427 - accuracy: 0.6463: 0s -\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6403 - accuracy: 0.6478\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6405 - accuracy: 0.6464\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6402 - accuracy: 0.6474\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6411 - accuracy: 0.6466\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6405 - accuracy: 0.6472\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6415 - accuracy: 0.6459\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6405 - accuracy: 0.6474\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6400 - accuracy: 0.6475\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6385 - accuracy: 0.6477\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6426 - accuracy: 0.6465\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6407 - accuracy: 0.6473\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6402 - accuracy: 0.6470\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6400 - accuracy: 0.6480\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6415 - accuracy: 0.6469\n",
      "2952/2952 [==============================] - 5s 2ms/step - loss: 0.6393 - accuracy: 0.6473\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6412 - accuracy: 0.6470\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6417 - accuracy: 0.6473\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6412 - accuracy: 0.6474\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6414 - accuracy: 0.6477\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6421 - accuracy: 0.6463\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6414 - accuracy: 0.6466\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6420 - accuracy: 0.6471\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6397 - accuracy: 0.6483\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6405 - accuracy: 0.6474\n",
      "2952/2952 [==============================] - 5s 2ms/step - loss: 0.6413 - accuracy: 0.6465\n",
      "2952/2952 [==============================] - 4s 1ms/step - loss: 0.6412 - accuracy: 0.6474\n",
      "1845/1845 [==============================] - 3s 1ms/step - loss: 0.6427 - accuracy: 0.6472\n",
      "1845/1845 [==============================] - 3s 1ms/step - loss: 0.6424 - accuracy: 0.6463\n",
      "1845/1845 [==============================] - 3s 1ms/step - loss: 0.6408 - accuracy: 0.6483\n",
      "1845/1845 [==============================] - 3s 1ms/step - loss: 0.6420 - accuracy: 0.6463\n",
      "1845/1845 [==============================] - 3s 1ms/step - loss: 0.6420 - accuracy: 0.6475\n",
      "1845/1845 [==============================] - 3s 1ms/step - loss: 0.6409 - accuracy: 0.6476\n",
      "1845/1845 [==============================] - 3s 1ms/step - loss: 0.6400 - accuracy: 0.6484\n",
      "1845/1845 [==============================] - 3s 2ms/step - loss: 0.6412 - accuracy: 0.6467\n",
      "1845/1845 [==============================] - 3s 2ms/step - loss: 0.6413 - accuracy: 0.6471\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6408 - accuracy: 0.6470\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6409 - accuracy: 0.6477\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6417 - accuracy: 0.6474\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6410 - accuracy: 0.6482\n",
      "1845/1845 [==============================] - 3s 2ms/step - loss: 0.6422 - accuracy: 0.6463\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6424 - accuracy: 0.6475\n",
      "1845/1845 [==============================] - 3s 1ms/step - loss: 0.6422 - accuracy: 0.6476: \n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6410 - accuracy: 0.6481\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6423 - accuracy: 0.6471\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6417 - accuracy: 0.6465\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6424 - accuracy: 0.6465\n",
      "1845/1845 [==============================] - 3s 1ms/step - loss: 0.6394 - accuracy: 0.6476\n",
      "1845/1845 [==============================] - 3s 2ms/step - loss: 0.6410 - accuracy: 0.6466\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6404 - accuracy: 0.6481\n",
      "1845/1845 [==============================] - 3s 1ms/step - loss: 0.6412 - accuracy: 0.6466\n",
      "1845/1845 [==============================] - 6s 3ms/step - loss: 0.6423 - accuracy: 0.6476\n",
      "1845/1845 [==============================] - 3s 1ms/step - loss: 0.6402 - accuracy: 0.6471\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6401 - accuracy: 0.6486\n",
      "1845/1845 [==============================] - 3s 1ms/step - loss: 0.6415 - accuracy: 0.6469\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6413 - accuracy: 0.6464\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6411 - accuracy: 0.6466\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6405 - accuracy: 0.6472\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6406 - accuracy: 0.6471\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6404 - accuracy: 0.6480\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6433 - accuracy: 0.6465\n",
      "1845/1845 [==============================] - 3s 1ms/step - loss: 0.6424 - accuracy: 0.6470\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6414 - accuracy: 0.6471\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6404 - accuracy: 0.6480\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6404 - accuracy: 0.6463\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6422 - accuracy: 0.6474\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6407 - accuracy: 0.6473\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6410 - accuracy: 0.6472\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6397 - accuracy: 0.6470\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6411 - accuracy: 0.6473\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6429 - accuracy: 0.6464\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6414 - accuracy: 0.6479\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6406 - accuracy: 0.6474\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6403 - accuracy: 0.6479\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6420 - accuracy: 0.6477\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6428 - accuracy: 0.6473\n",
      "1845/1845 [==============================] - 3s 1ms/step - loss: 0.6411 - accuracy: 0.6475\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6417 - accuracy: 0.6482\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6415 - accuracy: 0.6468\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6405 - accuracy: 0.6469\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6434 - accuracy: 0.6463\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6417 - accuracy: 0.6478\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6405 - accuracy: 0.6477\n",
      "1845/1845 [==============================] - 3s 1ms/step - loss: 0.6417 - accuracy: 0.6479\n",
      "1845/1845 [==============================] - 3s 2ms/step - loss: 0.6418 - accuracy: 0.6471\n",
      "1845/1845 [==============================] - 3s 1ms/step - loss: 0.6411 - accuracy: 0.6470\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6417 - accuracy: 0.6475\n",
      "1845/1845 [==============================] - 3s 1ms/step - loss: 0.6414 - accuracy: 0.6476\n",
      "1845/1845 [==============================] - 3s 1ms/step - loss: 0.6403 - accuracy: 0.6469\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6418 - accuracy: 0.6480\n",
      "1845/1845 [==============================] - 3s 1ms/step - loss: 0.6426 - accuracy: 0.6464: 0s - los\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6403 - accuracy: 0.6470\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6400 - accuracy: 0.6480\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6409 - accuracy: 0.6481: 0s - loss: 0.6415 - ac\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6408 - accuracy: 0.6475\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6393 - accuracy: 0.6474\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6412 - accuracy: 0.6473\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6415 - accuracy: 0.6471\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6410 - accuracy: 0.6468\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6421 - accuracy: 0.6478\n",
      "1845/1845 [==============================] - 3s 2ms/step - loss: 0.6421 - accuracy: 0.6470\n",
      "1845/1845 [==============================] - 3s 2ms/step - loss: 0.6424 - accuracy: 0.6475\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6416 - accuracy: 0.6475\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6410 - accuracy: 0.6476\n",
      "1845/1845 [==============================] - 2s 1ms/step - loss: 0.6416 - accuracy: 0.6479\n",
      "1845/1845 [==============================] - 3s 2ms/step - loss: 0.6413 - accuracy: 0.6464\n",
      "1845/1845 [==============================] - 3s 1ms/step - loss: 0.6415 - accuracy: 0.6471\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6403 - accuracy: 0.6478\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6423 - accuracy: 0.6474\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6410 - accuracy: 0.6483\n",
      "1687/1687 [==============================] - 3s 2ms/step - loss: 0.6426 - accuracy: 0.6469\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6407 - accuracy: 0.6473: 0s - l\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6408 - accuracy: 0.6476\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6405 - accuracy: 0.6479\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6410 - accuracy: 0.6475\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6410 - accuracy: 0.6469\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6416 - accuracy: 0.6456\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6412 - accuracy: 0.6474\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6409 - accuracy: 0.6474\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6416 - accuracy: 0.6477\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6413 - accuracy: 0.6462\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6422 - accuracy: 0.6474\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6422 - accuracy: 0.6475\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6412 - accuracy: 0.6483\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6415 - accuracy: 0.6470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6414 - accuracy: 0.6473\n",
      "1687/1687 [==============================] - 3s 2ms/step - loss: 0.6410 - accuracy: 0.6473\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6420 - accuracy: 0.6467\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6388 - accuracy: 0.6474\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6411 - accuracy: 0.6466\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6424 - accuracy: 0.6464\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6415 - accuracy: 0.6480\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6394 - accuracy: 0.6476\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6403 - accuracy: 0.6483\n",
      "1687/1687 [==============================] - 3s 2ms/step - loss: 0.6404 - accuracy: 0.6475\n",
      "1687/1687 [==============================] - 5s 3ms/step - loss: 0.6411 - accuracy: 0.6466: 3s - loss: 0\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6412 - accuracy: 0.6465\n",
      "1687/1687 [==============================] - 3s 2ms/step - loss: 0.6416 - accuracy: 0.6475\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6410 - accuracy: 0.6474\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6409 - accuracy: 0.6471\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6431 - accuracy: 0.6463\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6422 - accuracy: 0.6472\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6419 - accuracy: 0.6475\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6410 - accuracy: 0.6476\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6411 - accuracy: 0.6466\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6411 - accuracy: 0.6468\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6420 - accuracy: 0.6476\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6416 - accuracy: 0.6470\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6411 - accuracy: 0.6467\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6407 - accuracy: 0.6476\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6423 - accuracy: 0.6462\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6413 - accuracy: 0.6471: 0s - loss: 0.6423 \n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6409 - accuracy: 0.6476\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6398 - accuracy: 0.6471\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6422 - accuracy: 0.6471\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6414 - accuracy: 0.6469\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6419 - accuracy: 0.6472\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6414 - accuracy: 0.6480\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6416 - accuracy: 0.6476\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6421 - accuracy: 0.6479\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6425 - accuracy: 0.6463\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6414 - accuracy: 0.6478: 0s - loss: 0.642\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6420 - accuracy: 0.6469\n",
      "1687/1687 [==============================] - 3s 2ms/step - loss: 0.6410 - accuracy: 0.6480\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6408 - accuracy: 0.6475\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6429 - accuracy: 0.6473\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6418 - accuracy: 0.6468\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6414 - accuracy: 0.6471\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6407 - accuracy: 0.6479\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6411 - accuracy: 0.6465\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6435 - accuracy: 0.6459\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6430 - accuracy: 0.6477\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6402 - accuracy: 0.6477\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6411 - accuracy: 0.6482\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6419 - accuracy: 0.6477\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6420 - accuracy: 0.6462\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6422 - accuracy: 0.6461\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6412 - accuracy: 0.6475\n",
      "1687/1687 [==============================] - 3s 2ms/step - loss: 0.6424 - accuracy: 0.6474\n",
      "1687/1687 [==============================] - 2s 1ms/step - loss: 0.6421 - accuracy: 0.6469\n",
      "1687/1687 [==============================] - 3s 2ms/step - loss: 0.6430 - accuracy: 0.6458\n",
      "1687/1687 [==============================] - 4s 2ms/step - loss: 0.6424 - accuracy: 0.6472\n",
      "1687/1687 [==============================] - 4s 2ms/step - loss: 0.6409 - accuracy: 0.6477\n",
      "1687/1687 [==============================] - 4s 2ms/step - loss: 0.6412 - accuracy: 0.6477\n",
      "1687/1687 [==============================] - 3s 2ms/step - loss: 0.6423 - accuracy: 0.6466: 0s - los\n",
      "1687/1687 [==============================] - 3s 2ms/step - loss: 0.6412 - accuracy: 0.6467\n",
      "1687/1687 [==============================] - 3s 2ms/step - loss: 0.6419 - accuracy: 0.6470\n",
      "1476/1476 [==============================] - 2s 1ms/step - loss: 0.6405 - accuracy: 0.6475\n",
      "1476/1476 [==============================] - 3s 2ms/step - loss: 0.6418 - accuracy: 0.6468\n",
      "1476/1476 [==============================] - 2s 1ms/step - loss: 0.6391 - accuracy: 0.6477\n",
      "1476/1476 [==============================] - 2s 1ms/step - loss: 0.6426 - accuracy: 0.6464\n",
      "1476/1476 [==============================] - 2s 1ms/step - loss: 0.6408 - accuracy: 0.6476\n",
      "1476/1476 [==============================] - 4s 3ms/step - loss: 0.6419 - accuracy: 0.6461\n",
      "1476/1476 [==============================] - 3s 2ms/step - loss: 0.6403 - accuracy: 0.6480\n",
      "1476/1476 [==============================] - 3s 2ms/step - loss: 0.6408 - accuracy: 0.6458\n",
      "1476/1476 [==============================] - 2s 2ms/step - loss: 0.6417 - accuracy: 0.6470\n",
      "1476/1476 [==============================] - 4s 3ms/step - loss: 0.6429 - accuracy: 0.6460: 0s - los\n",
      "  32/1476 [..............................] - ETA: 2s - loss: 0.6664 - accuracy: 0.6203"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-43ca0bc5da2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#we need to fit our training set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#we get the best selection of parameters using best_params from the grid search object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 715\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#we need to fit our training set.\n",
    "\n",
    "grid_search = grid_search.fit(X_train,y_train)\n",
    "\n",
    "#we get the best selection of parameters using best_params from the grid search object\n",
    "\n",
    "best_param = grid_search.best_params_\n",
    "\n",
    "#we get the best accuracy score using best_score_\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "#NB: this process will take a while\n",
    "\n",
    "best_param, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
